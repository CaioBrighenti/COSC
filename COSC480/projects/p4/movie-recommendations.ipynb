{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd219f5b-9c65-4402-94f0-5e1933cc040f"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\renewcommand{\\b}{\\mathbf}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "$$\n",
    "\n",
    "\n",
    "# Movie Recommendations\n",
    "\n",
    "*Credits: this assignment adapted with permission from Dan Sheldon.*\n",
    "\n",
    "\n",
    "| user  | Moonlight | The Shape of Water   | Frozen | Moana     |\n",
    "|-------|-----------|----------------------|--------|-----------| \n",
    "|Alice  |   5       |          4           |    1   |           |\n",
    "|Bob    |           |          5           |        |    2      |\n",
    "|Carol  |           |                      |        |    5      |\n",
    "|David  |           |                      |    5   |    5      |\n",
    "|Eve    |   5       |          4           |        |           |\n",
    "\n",
    "\n",
    "What movie should I recommend to Bob?\n",
    "Will Carol like Frozen?\n",
    "\n",
    "**Goal**: Fill in entries of the \"rating matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "417fa0e4-6c70-4b9f-a42c-876215db961d"
    }
   },
   "source": [
    "# Problem Setup\n",
    "\n",
    "Let's formalize this as a machine learning problem. To make it concrete, let's load some data and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\caio brighenti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>Jungle2Jungle (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>Apocalypse Now (1979)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating                                title\n",
       "2070        0       242       1                 Jungle2Jungle (1997)\n",
       "2175        0        73       1  Faster Pussycat! Kill! Kill! (1965)\n",
       "984         0       101       2               Aristocats, The (1970)\n",
       "2400        0       236       2                 Jerry Maguire (1996)\n",
       "4364        0       179       3                Apocalypse Now (1979)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import scipy.io\n",
    "\n",
    "# Load train and test data\n",
    "data = scipy.io.loadmat('movies.mat')\n",
    "\n",
    "titles = [t[0] for t in data['movieData']['title'][0,0].ravel()]\n",
    "\n",
    "for x,y in data.items():\n",
    "    if isinstance(y, (np.ndarray)) and len(y)==1:\n",
    "        data[x] = np.asscalar(y)\n",
    "    elif isinstance(y, (np.ndarray)):\n",
    "        data[x] = y.ravel()\n",
    "\n",
    "nUsers    = data['nUsers']\n",
    "nMovies   = data['nMovies']\n",
    "userData  = data['userData']\n",
    "movieData = data['movieData']\n",
    "\n",
    "train_user   = data['train_user']-1   # matlab 1-index correction\n",
    "train_movie  = data['train_movie']-1  # matlab 1-index correction\n",
    "train_rating = data['train_rating']\n",
    "\n",
    "valid_user   = data['valid_user']-1   # matlab 1-index correction\n",
    "valid_movie  = data['valid_movie']-1  # matlab 1-index correction\n",
    "valid_rating = data['valid_rating']\n",
    "\n",
    "test_user    = data['test_user']-1    # matlab 1-index correction\n",
    "test_movie   = data['test_movie']-1   # matlab 1-index correction\n",
    "\n",
    "\n",
    "# Create a pandas data frame for training data to facilitate\n",
    "# visualization and inspection\n",
    "\n",
    "train_title = [titles[i] for i in train_movie]\n",
    "\n",
    "train_data = pd.DataFrame(data = {'user_id' : train_user, \n",
    "                                  'movie_id' : train_movie,\n",
    "                                  'rating' : train_rating,\n",
    "                                  'title': train_title}, \n",
    "                         columns = ['user_id', 'movie_id', 'rating', 'title'])\n",
    "\n",
    "# subsample to 5000 rows to more easily see a small sampling of ratings for each user\n",
    "train_data = train_data[:5000]\n",
    "\n",
    "# sort by user\n",
    "train_data = train_data.sort_values(by=['user_id', 'rating'])\n",
    "\n",
    "train_data.head() # display first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534"
    }
   },
   "source": [
    "## Training Data\n",
    "As we can see, the training data presents observed entries of the \"ratings\" matrix as list of triples $(i_k, j_k, r_k)$ where\n",
    "\n",
    "* $i_k$ is the user index of $k$th rating\n",
    "* $j_k$ is the movie index of $k$th rating\n",
    "* $r_k$ is the value of $k$th rating (1-5)\n",
    "\n",
    "In our code we will store the entries of the tuples in three separate 1d arrays of the same length, so the $k$th rating is represented by the values ``train_user[k]``, ``train_movie[k]``, and ``train_rating[k]``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "33f22eff-c565-4acc-bd8d-5d40678cb1e5"
    }
   },
   "source": [
    "## Problem Formulation\n",
    "\n",
    "Now, let's formulate the problem mathematically. Suppose there are $m$ users and $n$ movies. \n",
    "Let $R$ be the $m \\times n$ \"rating\" matrix, where $R_{ij}$ is the (possibly unknown) rating for user $i$ on movie $j$. \n",
    "\n",
    "Our training data gives us some of the entries of the rating matrix. Our goal\n",
    "is to learn a parametric model to predict entries that we don't observe.\n",
    "\n",
    "#### But Where are the Features?\n",
    "\n",
    "What sort of predictive model can we use for entries of $R$? \n",
    "\n",
    "In past learning problems we had *feature vectors* and we learned *weight vectors* to make predictions (using dot products). \n",
    "\n",
    "Now we do not have feature vectors. What should we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ad3301d3-5e9b-4f82-8180-9410aa5fd885"
    }
   },
   "source": [
    "## Matrix Factorization Model\n",
    "\n",
    "Our solution is to **learn weight vectors for both users and movies**. \n",
    "\n",
    "Let $\\u_i \\in \\R^d$ be the weight vector for use $i$ and $\\v_j \\in \\R^d$ be the weight vector for movie $j$. Then we can predict the rating for user $i$ on movie $j$ as:\n",
    "\n",
    "$$\n",
    "H_{ij} =\\u_i^T \\v_j\n",
    "$$\n",
    "\n",
    "Our goal is to learn weight vectors for every user and movie so that $R_{ij} \\approx H_{ij}$ for those entries of the rating matrix that we observe.\n",
    "\n",
    "**Problem statement**: \n",
    "Given observed entries of the rating matrix presented as triples $(i_k, j_k, r_k)$ for $k=1, \\ldots, n_{\\text{train}}$, find weight vectors $\\mathbf{u_i}$ for each user $i$ and $\\mathbf{v}_j$ for each movie $j$ such that:\n",
    "$$\n",
    "r_k \\approx \\mathbf{u_{i_k}}^T \\mathbf{v_{j_k}}, \\quad k=1, 2, \\ldots, n_{\\text{train}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f68ec3c-1530-4569-abd9-306b981a638b"
    }
   },
   "source": [
    "## Why is This Called Matrix Factorization?\n",
    "\n",
    "* Place the user weight vectors $\\u_i$ into the rows of a matrix\n",
    "  $U$ and the movie feature vectors $\\v_j$ into\n",
    "  the rows of a matrix $V$\n",
    "\n",
    "    $$ \n",
    "    \\newcommand{\\line}{-}\n",
    "    U =\n",
    "        \\begin{bmatrix}\n",
    "            \\line \\u_1^T \\line \\\\\n",
    "            \\line \\u_2^T \\line \\\\\n",
    "            \\ldots \\\\\n",
    "            \\line \\u_m^T \\line \\\\\n",
    "        \\end{bmatrix} \\in \\R^{m \\times d}\n",
    "    \\qquad\n",
    "    V =\n",
    "        \\begin{bmatrix}\n",
    "            \\line \\v_1^T \\line \\\\\n",
    "            \\line \\v_2^T \\line \\\\\n",
    "            \\ldots \\\\\n",
    "            \\line \\v_n^T \\line \\\\\n",
    "        \\end{bmatrix} \\in \\R^{n \\times d}\n",
    "    $$\n",
    "\n",
    "* Consider the product $U V^T$:\n",
    "\n",
    "    $$\n",
    "    \\boxed{\n",
    "        \\begin{array}{c}\n",
    "            \\\\\n",
    "            U \\\\\n",
    "            \\\\\n",
    "        \\end{array}\n",
    "        }\n",
    "    \\boxed{\n",
    "        \\begin{array}{c}\n",
    "            \\ \\ \\ V^T \\ \\ \\ \n",
    "        \\end{array}\n",
    "        }\n",
    "    $$\n",
    "  \n",
    "* It is easy to check that $(i,j)$ entry of $UV^T$ is equal to $\\u_i^T\n",
    "  \\v_j$, which is our prediction for the $(i,j)$ entry of $R$\n",
    "\n",
    "* In other words, our model is that $R \\approx U V^T$ (a **factorization**\n",
    "  of $R$)\n",
    "\n",
    "* We choose $U$ and $V$ to get good predictions for those entries of\n",
    "  $R$ that we can observe. As long as we don't overfit, this gives us\n",
    "  power to generalize to entries we don't observe\n",
    "  \n",
    "* The \"hidden dimension\" $d$ (the length of each weight vector) is a hyperparameter\n",
    "  that must be tuned with hold-out data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c743c2d0-2dc4-4101-881c-01053255f632"
    }
   },
   "source": [
    "## Your Job: Solve the Learning Problem \n",
    "\n",
    "* Formulate a squared error cost function corresponding to the problem statement above.\n",
    "* Add regularization for *every* user weight vector $\\u_i$ and movie weight vector $\\v_j$ to get a regularized cost function\n",
    "* Write down the partial derivatives of your regularized cost function with\n",
    "  respect to the entries of $\\u_i$ and $\\v_j$\n",
    "* Plug the partial derivatives into stochastic gradient descent (SGD)\n",
    "  and write down the update rule\n",
    "* Implement SGD\n",
    "* Tune parameters (e.g., dimension $d$, regularization parameter) get good performance on the validation set\n",
    "\n",
    "\n",
    "Your final notebook should include some analysis (preferably with some figures/statistics reported).  What model did you develop?  What process did you use to fit it?  What are the final parameters?  What intermediate results did you generate that led you to this final parameterization? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "25aa92a1-20c9-4206-9133-ab31f96cb321"
    }
   },
   "source": [
    "* Submit predictions on test set. \n",
    "* Evaluation: root-mean squared error (RMSE) on test set\n",
    "\n",
    "    $$ \\text{RMSE} = \\sqrt{\\frac{1}{n_{\\text{test}}}\\sum_{(i,j) \\in \\text{test set}} (H_{ij} - R_{ij})^2}$$\n",
    "\n",
    "* A *portion* of your grade will be based on test set performance using the following guidelines:\n",
    "\n",
    "| RMSE   |  grade  |\n",
    "|--------|---------|\n",
    "|>  1.0  |  60%    |\n",
    "|<= 1.0  |  80%    |\n",
    "|<= 0.97 |  90%    |\n",
    "|<= 0.95 |   95%   |\n",
    "|<= 0.94 |  100%   ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "597ff142-4663-4ddb-bc6f-7b71e1127cc0"
    }
   },
   "source": [
    "## (Review on your own) Model Extension: Add Biases\n",
    "\n",
    "To get really great performance, consider this extended model for a predicted rating:\n",
    "\n",
    "$$\n",
    "H_{ij} = \\mu + a_i + b_j + \\u_i^T \\v_j\n",
    "$$\n",
    "\n",
    "This adds several terms to the prediction for user $i$ on movie $j$:\n",
    "\n",
    "* $\\mu$ is an overall baseline rating. For example, the overall average rating of all users\n",
    "  on all movies may be $\\mu = 3.3$\n",
    "  \n",
    "* $a_i$ is a user-specific adjustment or \"bias\". For example, perhaps Alice\n",
    "  really loves movies and gives them all high ratings. Then, her bias \n",
    "  might be $a_i = +0.4$. But Bob is hard to please, so his bias is $a_i = -0.7$.\n",
    "  \n",
    "* $b_j$ is a movie-specific bias. For example, perhaps Inside Out is universally\n",
    "  loved, so its bias is $b_j = +0.7$. A really bad movie would have a negative bias.\n",
    "\n",
    "The set of parameters of this model includes:\n",
    "\n",
    "* $\\mu$ \n",
    "* $a_i$, $i=1,\\ldots, m$\n",
    "* $b_j$, $j=1,\\ldots, n$\n",
    "* $\\u_i \\in \\R^d$, $i=1,\\ldots, m$\n",
    "* $\\v_j \\in \\R^d$, $j=1,\\ldots, n$\n",
    "\n",
    "To learn these parameters, derive partial derivatives of the regularized\n",
    "cost function with respect to *all* of the above parameters, and update\n",
    "them all within your stochastic gradient descent loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "[Matrix Factorization Techniques for Recommender\n",
    "Systems](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    "by Yehuda Koren, Robert Bell and Chris Volinsky\n",
    "\n",
    "* Authors were on the winning team of Netflix prize\n",
    "\n",
    "* Paper includes algorithms---but beware different notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Familiarize Yourself With Variables\n",
    "\n",
    "Here are the variables we populated while loading the data above --- make sure you run that cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Metadata\n",
    "#     \n",
    "#     nUsers     # of users\n",
    "#     nMovies    # of movies\n",
    "#     titles     list of movie titles\n",
    "#\n",
    "#\n",
    "# 2) Training data (60K ratings). This consists of three 1d arrays, \n",
    "#    each of length 60K:\n",
    "#\n",
    "#      train_user, train_movie, train_rating\n",
    "#\n",
    "#    The entries specify the ratings:\n",
    "#   \n",
    "#      train_user[k]    user index  of kth rating\n",
    "#      train_movie[k]   movie index of kth rating\n",
    "#      train_rating[k]  value (1-5) of kth rating\n",
    "#\n",
    "# 2) Validation data (20K ratings). Three vectors of length 20K:\n",
    "#\n",
    "#      valid_user, valid_movie, valid_rating\n",
    "#   \n",
    "#    Use this to evaluate your model and tune parameters.\n",
    "#    \n",
    "# 3) Test set (20K user-movie pairs without ratings):\n",
    "#\n",
    "#      test_user, test_movie\n",
    "#\n",
    "#    You will create predictions for these pairs and submit them for \n",
    "#    grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Look at the Prediction Method\n",
    "\n",
    "To make things concrete, first take a look at the prediction method below. This is just a stub for now that returns the same value ``mu`` for every prediction. Later you will update this to make predictions given the weight vectors and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "46a5a100-4e08-43e9-a313-ea1a0f06d149"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(h, r):\n",
    "    resid = h - r\n",
    "    cost = np.sqrt(np.mean(resid**2))\n",
    "    return cost\n",
    "\n",
    "def predict(user, movie, U, V, mu, a, b):\n",
    "    '''\n",
    "    PREDICT Make predictions for user/movie pairs\n",
    "    Inputs: \n",
    "      model parameters\n",
    "      user               vector of users\n",
    "      movie              vector of movies\n",
    "    \n",
    "    Output:\n",
    "      predictions        vector of predictions\n",
    "    '''    \n",
    "    user_weights = U[user,:]\n",
    "    movie_weights = V[movie,:]\n",
    "    user_biases = a[user]\n",
    "    movie_biases = b[movie]\n",
    "    predictions = np.sum(np.multiply(user_weights,movie_weights),axis=1)\n",
    "    predictions = predictions + mu + user_biases + movie_biases\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Learning and Validation\n",
    "\n",
    "Write code here to do the learning and validation. Stubs are provided. Make sure you derive the partial derivatives on paper before you try to code them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Parameter Selection\n",
    "\n",
    "The matrix factorization approach has three parameters than can be tuned to improve performance. These are the hidden dimension of the weight vectors $d$, the gradient descent step size, and the regularization parameter $\\lambda$. Given that the best regularization parameter depends on the degree of overfitting hapepning, and increasing the dimension $d$ is likely to increase the risk of overfitting, these two parameters must be tuned in unison. To do this, I ran SGD for 50 iterations on a variety of pairs of $d$ and $\\lambda$ and found the combination that resulted in the best validation error.\n",
    "\n",
    "My implementation of matrix factorization through SGD uses the enhanced model with user and movie biases, as well as a global average bias term. The formal cost function for this model is as follows\n",
    "\n",
    "$$ Q = \\sum_{ij} [(r_{ij} - u_{i}v_{j} - \\mu - a_i - b_j) + \\lambda(||u_{i}||^2 + ||v_{j}||^2 + a^2 + b^2 )]$$\n",
    "\n",
    "On each iteration of SGD, the matrix of observations is shuffled, then each rating is used one-by-one to update the user weights, movie weights, user bias, and movie bias. These updates are calculated as follows:\n",
    "\n",
    "$ u_i = u_i + \\eta(e \\cdot v_j - \\lambda \\cdot u_i) $ \n",
    "\n",
    "$ v_j = v_j + \\eta(e \\cdot u_i - \\lambda \\cdot v_j) $\n",
    "\n",
    "$ a_i = \\eta(e - \\lambda \\cdot a_i))$\n",
    "\n",
    "$ b_j = \\eta(e - \\lambda \\cdot b_j))$\n",
    "\n",
    "Where $e$ is the error $e_{ij} = r_{ij} - h_{ij}$, where $h_{ij}$ is the prediction for user $i$ and movie $j$.\n",
    "\n",
    "The results of this cross validation are shown below in a surface plot of $d$, $lambda$, and the vaidation error. The best combination of these two parameters is stored in a variable and printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [1:33:57<00:00, 563.77s/it]\n"
     ]
    }
   ],
   "source": [
    "import mf\n",
    "from mf import error_function, sgd_minimal\n",
    "from tqdm import tqdm\n",
    "############################################\n",
    "# Initialize parameters\n",
    "############################################\n",
    "\n",
    "mu = np.mean(train_rating)\n",
    "a  = np.zeros(nUsers)\n",
    "b  = np.zeros(nMovies)\n",
    "num_iters = 50\n",
    "\n",
    "############################################\n",
    "# Validate d and lambda\n",
    "############################################\n",
    "# init vectors of possible dimensions and reg. parameters\n",
    "d_vector = np.arange(1,100,step=10)\n",
    "num_d = len(d_vector)\n",
    "lambda_vector = np.arange(0,1,step=0.1)\n",
    "num_lambda = len(lambda_vector)\n",
    "params = np.zeros(shape=(num_d*num_lambda,4))\n",
    "# loop through each combination\n",
    "row = 0\n",
    "for i in tqdm(range(num_d)):\n",
    "    for j in range(num_lambda):\n",
    "        # pull out params and init U,V\n",
    "        d = d_vector[i]\n",
    "        U  = np.random.randn(nUsers, d)  *.01 # User weights\n",
    "        V  = np.random.randn(nMovies, d) *.01 # Movie features\n",
    "        lambda_reg = lambda_vector[j]\n",
    "        # train model\n",
    "        U,V,a,b = sgd_minimal(num_iters,train_user,train_movie,train_rating,.01,lambda_reg,U,V,mu,a,b)\n",
    "        # calc errors\n",
    "        train_predictions = predict(train_user, train_movie, U, V, mu, a, b)\n",
    "        valid_predictions = predict(valid_user, valid_movie, U, V, mu, a, b)\n",
    "\n",
    "        train_rmse = rmse(train_predictions, train_rating)\n",
    "        valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "        # store in params matrix\n",
    "        params[row,:] = [d,lambda_reg,train_rmse,valid_rmse]\n",
    "        row = row + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1386ee0e4b6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'3d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_trisurf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation RMSE for varying d and lambda \\n Trained on 50 iterations of SGD\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# surface plot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_trisurf(params[:,0],params[:,1],params[:,3])\n",
    "plt.title(\"Validation RMSE for varying d and lambda \\n Trained on 50 iterations of SGD\")\n",
    "plt.xlabel(\"d\")\n",
    "plt.ylabel(\"lambda\")\n",
    "plt.zlabel(\"valid RMSE\")\n",
    "\n",
    "# find optimal parameters\n",
    "index_min = np.argmin(params[:,3])\n",
    "d_best = int(params[index_min,0])\n",
    "lambda_best = params[index_min,1]\n",
    "print('best parameters: hidden dimension=%.0f, regularization parameter=%.1f' % (d_best, lambda_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cross validation shows the ideal combination of parameters is $d=91$ and $\\lambda = 0.1$. \n",
    "\n",
    "Next, I performed cross validation to select the ideal step size. I did this by training models on a series of step sizes and selecting the one with the best cross validation error. I experimented with varying the number of iterations for this cross validation step, but results were unchanged when I increased the number of iterations to 100. \n",
    "\n",
    "The train and validation error for each step size is shown in the barplot below, and the best step size is stored in a variable and printed to the console. I found that the ideal step size was 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [05:45<00:00, 57.56s/it]\n"
     ]
    }
   ],
   "source": [
    "import mf\n",
    "from mf import error_function, sgd_minimal\n",
    "from tqdm import tqdm\n",
    "############################################\n",
    "# Initialize parameters\n",
    "############################################\n",
    "mu = np.mean(train_rating)\n",
    "a  = np.zeros(nUsers)\n",
    "b  = np.zeros(nMovies)\n",
    "num_iters = 50\n",
    "\n",
    "############################################\n",
    "# Validate step size\n",
    "############################################\n",
    "# init vectors of possible step sizes\n",
    "step_sizes = [0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
    "num_steps = len(step_sizes)\n",
    "params_steps = np.zeros(shape=(num_steps,3))\n",
    "# loop through each step size\n",
    "for i in tqdm(range(num_steps)):\n",
    "    # pull out params and init U,V\n",
    "    U  = np.random.randn(nUsers, d_best)  *.01 # User weights\n",
    "    V  = np.random.randn(nMovies, d_best) *.01 # Movie features\n",
    "    step_size = step_sizes[i]\n",
    "    # train model\n",
    "    U,V,a,b = sgd_minimal(num_iters,train_user,train_movie,train_rating,step_size,lambda_best,U,V,mu,a,b)\n",
    "    # calc errors\n",
    "    train_predictions = predict(train_user, train_movie, U, V, mu, a, b)\n",
    "    valid_predictions = predict(valid_user, valid_movie, U, V, mu, a, b)\n",
    "\n",
    "    train_rmse = rmse(train_predictions, train_rating)\n",
    "    valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "    # store in params matrix\n",
    "    params_steps[i,:] = [step_size,train_rmse,valid_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b06bea9ba725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# set height of bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbars1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mbars2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params_steps' is not defined"
     ]
    }
   ],
   "source": [
    "### plot code adapted from https://python-graph-gallery.com/11-grouped-barplot/\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = params_steps[:,1]\n",
    "bars2 = params_steps[:,2]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1,width=barWidth, edgecolor='white', label='train')\n",
    "plt.bar(r2, bars2, width=barWidth, edgecolor='white', label='valid')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('step size', fontweight='bold')\n",
    "plt.ylabel('RMSE', fontweight='bold')\n",
    "plt.title('RMSE for varying step sizes \\n Models trained on 50 iterations of SGD')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], params_steps[:,0])\n",
    "\n",
    "# Add min lines\n",
    "min_rmse_train = min(params_steps[:,1])\n",
    "min_rmse_valid = min(params_steps[:,2])\n",
    "plt.axhline(y=min_rmse_train,color=\"#1f77b4\")\n",
    "plt.axhline(y=min_rmse_valid,color=\"#ff7f0e\")\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_step_size = step_sizes[np.argmin(params_steps[:,2])]\n",
    "print(\"Best step size is: \" + str(best_step_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Fitting\n",
    "\n",
    "Using the cross validated parameters of $d=91$, $\\lambda = 0.1$ and a step size of $0.01$, I trained a final model using 100 iterations. In order to identify whether overfitting was ocurring, I stored the train and validation RMSE after each iteration and plotted them below. This plot suggested some overfitting was occuring, as the train RMSE continued to decrease while the validation RMSE stabilized or increased slightly.\n",
    "\n",
    "In order to avoid overtraining the model, I used validation RMSE history to identify at which iteration the validation error was minimized, then retrained my model using only that many iterations. This does not necessarily guarantee the exact same validation RMSE as in the original plotted model, given that the training is a stochastic process, but it will certainly ameloriate overfitting.\n",
    "\n",
    "The final train and validation errors are printed to the console after the final model is fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training: train_rmse=0.730, valid_rmse=0.914\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import mf\n",
    "from mf import error_function, sgd, sgd_minimal\n",
    "############################################\n",
    "# Tunable parameters (you will add more)\n",
    "############################################\n",
    "\n",
    "nDims = d_best\n",
    "\n",
    "############################################\n",
    "# Initialize parameters\n",
    "############################################\n",
    "\n",
    "mu = np.mean(train_rating)\n",
    "a  = np.zeros(nUsers)\n",
    "b  = np.zeros(nMovies)\n",
    "U  = np.random.randn(nUsers, nDims)  *.01 # User weights\n",
    "V  = np.random.randn(nMovies, nDims) *.01 # Movie features\n",
    "\n",
    "############################################\n",
    "# Training and validation\n",
    "############################################\n",
    "\n",
    "# TODO: write code to train model and evaluate performance on validation set\n",
    "# \n",
    "#  You are encouraged to define functions in mf.py and import them here.\n",
    "#\n",
    "#  predict() is a stub that predicts the overall mean for all user-movie\n",
    "#  pairs. Update it to take more parameters and make real predictions.\n",
    "\n",
    "\n",
    "### own code\n",
    "train_predictions = predict(train_user, train_movie, U, V, mu, a, b)\n",
    "valid_predictions = predict(valid_user, valid_movie, U, V, mu, a, b)\n",
    "\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "\n",
    "U,V,a,b,train_rmse_hist,valid_rmse_hist = sgd(100,train_user,train_movie,train_rating,best_step_size,lambda_best,U,V,mu,a,b,valid_user, valid_movie,valid_rating)\n",
    "\n",
    "train_predictions = predict(train_user, train_movie, U, V, mu, a, b)\n",
    "valid_predictions = predict(valid_user, valid_movie, U, V, mu, a, b)\n",
    "\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "\n",
    "## error history\n",
    "min_valid = np.argmin(valid_rmse_hist)\n",
    "plt.plot(train_rmse_hist)\n",
    "plt.plot(valid_rmse_hist)\n",
    "plt.title(\"RMSE over iterations of gradient descent \\n d = %.0f, lambda = %.1f, step size = %.2f\" % (d_best,lambda_best,best_step_size))\n",
    "plt.legend(['Train','Validation'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.axvline(x=min_valid)\n",
    "\n",
    "# FINAL TRAINING\n",
    "# reset weights\n",
    "a  = np.zeros(nUsers)\n",
    "b  = np.zeros(nMovies)\n",
    "U  = np.random.randn(nUsers, nDims)  *.01 # User weights\n",
    "V  = np.random.randn(nMovies, nDims) *.01 # Movie features\n",
    "\n",
    "# train with optimal parameters\n",
    "U,V,a,b = sgd_minimal(min_valid,train_user,train_movie,train_rating,.01,lambda_best,U,V,mu,a,b)\n",
    "train_predictions = predict(train_user, train_movie, U, V, mu, a, b)\n",
    "valid_predictions = predict(valid_user, valid_movie, U, V, mu, a, b)\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "print('after training: train_rmse=%.3f, valid_rmse=%.3f' % (train_rmse, valid_rmse))\n",
    "\n",
    "\n",
    "############################################\n",
    "# Testing\n",
    "############################################\n",
    "\n",
    "# Make and save predictions for test set\n",
    "test_predictions = predict(test_user, test_movie, U, V,mu, a, b)\n",
    "\n",
    "np.savetxt('test_predictions.txt', test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Material: Inspect Predictions for Different Users\n",
    "\n",
    "After you have learned a good model, you may wish to interpret what it has learned. We can do this by looking at the most positive and most negative predictions for different users\n",
    "(or the movies that are bumped up or down from the baseline the most).\n",
    "\n",
    "Read and run the code below to see if you can understand the predictions. (Note: the predictions won't make sense until you have learned a good model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "9c3800be-12ec-43a7-b24a-8cf543daf831"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User 0 ***\n",
      "  Top movies\n",
      "    +0.6263  Monty Python's Life of Brian (1979)\n",
      "    +0.5918  City of Lost Children, The (1995)\n",
      "    +0.5660  Swingers (1996)\n",
      "    +0.5500  Cook the Thief His Wife & Her Lover, The (1989)\n",
      "    +0.5453  Sleeper (1973)\n",
      "    +0.5449  Big Night (1996)\n",
      "    +0.5433  Legends of the Fall (1994)\n",
      "    +0.5423  Three Colors: Blue (1993)\n",
      "\n",
      "  Bottom movies\n",
      "    -0.8412  Homeward Bound: The Incredible Journey (1993)\n",
      "    -0.7825  Kull the Conqueror (1997)\n",
      "    -0.7599  Jungle2Jungle (1997)\n",
      "    -0.7259  George of the Jungle (1997)\n",
      "    -0.7115  Dirty Dancing (1987)\n",
      "    -0.6559  First Knight (1995)\n",
      "    -0.6538  My Best Friend's Wedding (1997)\n",
      "    -0.6424  McHale's Navy (1997)\n",
      "\n",
      "*** User 1 ***\n",
      "  Top movies\n",
      "    +0.4301  Old Man and the Sea, The (1958)\n",
      "    +0.3511  English Patient, The (1996)\n",
      "    +0.3483  Amistad (1997)\n",
      "    +0.3313  Kiss Me, Guido (1997)\n",
      "    +0.3194  Love Jones (1997)\n",
      "    +0.3188  Boogie Nights (1997)\n",
      "    +0.3160  Welcome to the Dollhouse (1995)\n",
      "    +0.3119  Graduate, The (1967)\n",
      "\n",
      "  Bottom movies\n",
      "    -0.5535  Liar Liar (1997)\n",
      "    -0.3826  George of the Jungle (1997)\n",
      "    -0.3773  Saint, The (1997)\n",
      "    -0.3632  Jungle2Jungle (1997)\n",
      "    -0.3534  Volcano (1997)\n",
      "    -0.3411  Down Periscope (1996)\n",
      "    -0.3328  Angels in the Outfield (1994)\n",
      "    -0.3273  Congo (1995)\n",
      "\n",
      "*** User 2 ***\n",
      "  Top movies\n",
      "    +1.0688  Boogie Nights (1997)\n",
      "    +0.8321  Paradise Lost: The Child Murders at Robin Hood Hills (1996)\n",
      "    +0.8071  Wag the Dog (1997)\n",
      "    +0.7837  Mother (1996)\n",
      "    +0.7655  Jackie Brown (1997)\n",
      "    +0.5493  Kiss Me, Guido (1997)\n",
      "    +0.5105  Apostle, The (1997)\n",
      "    +0.5022  Keys to Tulsa (1997)\n",
      "\n",
      "  Bottom movies\n",
      "    -0.7499  I Know What You Did Last Summer (1997)\n",
      "    -0.7282  G.I. Jane (1997)\n",
      "    -0.6820  Scream 2 (1997)\n",
      "    -0.6694  Rainmaker, The (1997)\n",
      "    -0.6566  Devil's Own, The (1997)\n",
      "    -0.5879  Kiss the Girls (1997)\n",
      "    -0.5735  Nixon (1995)\n",
      "    -0.5546  House of Yes, The (1997)\n",
      "\n",
      "*** User 3 ***\n",
      "  Top movies\n",
      "    +0.5265  8 1/2 (1963)\n",
      "    +0.5135  Trainspotting (1996)\n",
      "    +0.5032  Boogie Nights (1997)\n",
      "    +0.4995  Clockwork Orange, A (1971)\n",
      "    +0.4973  To Die For (1995)\n",
      "    +0.4783  Lost Highway (1997)\n",
      "    +0.4722  Ghost in the Shell (Kokaku kidotai) (1995)\n",
      "    +0.4519  Blue in the Face (1995)\n",
      "\n",
      "  Bottom movies\n",
      "    -0.5673  Client, The (1994)\n",
      "    -0.5421  Firm, The (1993)\n",
      "    -0.5367  American President, The (1995)\n",
      "    -0.5209  City Slickers II: The Legend of Curly's Gold (1994)\n",
      "    -0.5099  Kull the Conqueror (1997)\n",
      "    -0.4791  Another Stakeout (1993)\n",
      "    -0.4692  Young Guns (1988)\n",
      "    -0.4432  Striking Distance (1993)\n",
      "\n",
      "*** User 4 ***\n",
      "  Top movies\n",
      "    +0.9444  Chasing Amy (1997)\n",
      "    +0.9321  Forbidden Planet (1956)\n",
      "    +0.8539  Night of the Living Dead (1968)\n",
      "    +0.8122  8 1/2 (1963)\n",
      "    +0.8040  Duck Soup (1933)\n",
      "    +0.7831  Mars Attacks! (1996)\n",
      "    +0.7545  Fear of a Black Hat (1993)\n",
      "    +0.7357  Clockwork Orange, A (1971)\n",
      "\n",
      "  Bottom movies\n",
      "    -1.1909  Grease (1978)\n",
      "    -0.9497  Bastard Out of Carolina (1996)\n",
      "    -0.8617  American President, The (1995)\n",
      "    -0.8460  Bridges of Madison County, The (1995)\n",
      "    -0.8335  Dirty Dancing (1987)\n",
      "    -0.8043  Sound of Music, The (1965)\n",
      "    -0.8003  On Golden Pond (1981)\n",
      "    -0.7706  Black Beauty (1994)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_movies = range(nMovies)\n",
    "\n",
    "def get_lowest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    return most_negative\n",
    "\n",
    "def get_highest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    most_positive = most_negative[::-1]\n",
    "    return most_positive\n",
    "\n",
    "k = 8\n",
    "all_users = range(nUsers)\n",
    "users_to_examine = all_users[0:5]\n",
    "\n",
    "for user in users_to_examine:\n",
    "\n",
    "    # Changes from baseline movie predictions for this user\n",
    "    delta = np.dot(V, U[user,:])  \n",
    "\n",
    "    print('*** User %d ***' % (user))\n",
    "    print('  Top movies')\n",
    "    for i in get_highest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n",
    "    \n",
    "    print('  Bottom movies')\n",
    "    for i in get_lowest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "496c99a6-522e-4637-aeda-aed1d27ea1a5"
    }
   },
   "source": [
    "## More Bonus Material: Interpretation of Weight Vectors as Features\n",
    "\n",
    "* So far we have described both $\\u_i$ and $\\v_j$ as *weight vectors* (since we don't have any features of movies and users). But, it is possible to interpret one or both of these vectors as **learned features**. \n",
    "\n",
    "* For example, the first learned feature may discover a preference for comedy vs. drama. In this case:\n",
    "    * The user feature value $u_{i1}$ should be high if the user likes comedies and low if the user likes dramas better.\n",
    "    * The movie feature value $v_{j1}$ should be high if the movie is a comedy and low if it is a drama. \n",
    "    \n",
    "* Similarly, feature 2 might describe whether a movie is geared toward kids or adults\n",
    "\n",
    "* In practice, the feature interpretations often find recognizable patterns but are not quite so clean to describe as the two examples above.\n",
    "\n",
    "Run the code below to examine the movies with the highest and lowest feature values for some of the features in your learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "8d3aa776-2611-48aa-b921-84ff8f528fdf"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature 0 ***\n",
      "  Movies with highest feature value\n",
      "    +0.4599  I Know What You Did Last Summer (1997)\n",
      "    +0.3487  Lost Highway (1997)\n",
      "    +0.3428  Beavis and Butt-head Do America (1996)\n",
      "    +0.2823  Army of Darkness (1993)\n",
      "    +0.2692  Soul Food (1997)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.3162  Piano, The (1993)\n",
      "    -0.3098  Natural Born Killers (1994)\n",
      "    -0.2776  Steel (1997)\n",
      "    -0.2733  Matilda (1996)\n",
      "    -0.2634  That Darn Cat! (1997)\n",
      "\n",
      "*** Feature 1 ***\n",
      "  Movies with highest feature value\n",
      "    +0.2772  Tin Cup (1996)\n",
      "    +0.2513  Die Hard: With a Vengeance (1995)\n",
      "    +0.2473  Star Trek: The Motion Picture (1979)\n",
      "    +0.2352  Client, The (1994)\n",
      "    +0.2309  Star Trek III: The Search for Spock (1984)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2603  Young Poisoner's Handbook, The (1995)\n",
      "    -0.2442  Boogie Nights (1997)\n",
      "    -0.2286  Trainspotting (1996)\n",
      "    -0.2271  George of the Jungle (1997)\n",
      "    -0.2218  Celluloid Closet, The (1995)\n",
      "\n",
      "*** Feature 2 ***\n",
      "  Movies with highest feature value\n",
      "    +0.2822  Paradise Lost: The Child Murders at Robin Hood Hills (1996)\n",
      "    +0.2492  Interview with the Vampire (1994)\n",
      "    +0.2471  Bad Taste (1987)\n",
      "    +0.2447  Winter Guest, The (1997)\n",
      "    +0.2426  Natural Born Killers (1994)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.3574  Matilda (1996)\n",
      "    -0.2734  Steel (1997)\n",
      "    -0.2660  Man Who Knew Too Little, The (1997)\n",
      "    -0.2587  Star Trek VI: The Undiscovered Country (1991)\n",
      "    -0.2540  So I Married an Axe Murderer (1993)\n",
      "\n",
      "*** Feature 3 ***\n",
      "  Movies with highest feature value\n",
      "    +0.3375  Fantasia (1940)\n",
      "    +0.3253  Kingpin (1996)\n",
      "    +0.2763  Jungle2Jungle (1997)\n",
      "    +0.2689  Beavis and Butt-head Do America (1996)\n",
      "    +0.2667  Black Sheep (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2865  Piano, The (1993)\n",
      "    -0.2444  Tales from the Hood (1995)\n",
      "    -0.2253  Stand by Me (1986)\n",
      "    -0.2212  Clockwork Orange, A (1971)\n",
      "    -0.2175  Angels and Insects (1995)\n",
      "\n",
      "*** Feature 4 ***\n",
      "  Movies with highest feature value\n",
      "    +0.4082  Happy Gilmore (1996)\n",
      "    +0.3619  Starship Troopers (1997)\n",
      "    +0.3613  Dumb & Dumber (1994)\n",
      "    +0.3240  Kingpin (1996)\n",
      "    +0.3035  Seven (Se7en) (1995)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2733  Mystery Science Theater 3000: The Movie (1996)\n",
      "    -0.2273  City of Lost Children, The (1995)\n",
      "    -0.2270  Mother (1996)\n",
      "    -0.2206  Cold Comfort Farm (1995)\n",
      "    -0.2050  Kids in the Hall: Brain Candy (1996)\n",
      "\n",
      "*** Feature 5 ***\n",
      "  Movies with highest feature value\n",
      "    +0.2561  Chasing Amy (1997)\n",
      "    +0.2509  Fifth Element, The (1997)\n",
      "    +0.2253  Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)\n",
      "    +0.2110  Forrest Gump (1994)\n",
      "    +0.2105  Mortal Kombat (1995)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2675  Breakfast at Tiffany's (1961)\n",
      "    -0.2670  How to Make an American Quilt (1995)\n",
      "    -0.2654  Grease (1978)\n",
      "    -0.2614  So I Married an Axe Murderer (1993)\n",
      "    -0.2377  Sound of Music, The (1965)\n",
      "\n",
      "*** Feature 6 ***\n",
      "  Movies with highest feature value\n",
      "    +0.2984  Forbidden Planet (1956)\n",
      "    +0.2913  Army of Darkness (1993)\n",
      "    +0.2858  Die Hard 2 (1990)\n",
      "    +0.2839  Mallrats (1995)\n",
      "    +0.2692  Princess Bride, The (1987)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.3080  Pinocchio (1940)\n",
      "    -0.3066  Birdcage, The (1996)\n",
      "    -0.2773  Free Willy (1993)\n",
      "    -0.2750  How to Make an American Quilt (1995)\n",
      "    -0.2584  Assassins (1995)\n",
      "\n",
      "*** Feature 7 ***\n",
      "  Movies with highest feature value\n",
      "    +0.3554  Godfather, The (1972)\n",
      "    +0.3137  Supercop (1992)\n",
      "    +0.2667  Empire Strikes Back, The (1980)\n",
      "    +0.2558  Die Hard (1988)\n",
      "    +0.2427  Return of the Jedi (1983)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.3464  Steel (1997)\n",
      "    -0.3186  George of the Jungle (1997)\n",
      "    -0.2929  Midnight in the Garden of Good and Evil (1997)\n",
      "    -0.2708  Mr. Holland's Opus (1995)\n",
      "    -0.2707  Home for the Holidays (1995)\n",
      "\n",
      "*** Feature 8 ***\n",
      "  Movies with highest feature value\n",
      "    +0.3641  Another Stakeout (1993)\n",
      "    +0.3458  Ace Ventura: Pet Detective (1994)\n",
      "    +0.3388  City Slickers II: The Legend of Curly's Gold (1994)\n",
      "    +0.3276  How to Make an American Quilt (1995)\n",
      "    +0.3058  Grease (1978)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2818  Event Horizon (1997)\n",
      "    -0.2712  Scream 2 (1997)\n",
      "    -0.2587  Aristocats, The (1970)\n",
      "    -0.2471  Diabolique (1996)\n",
      "    -0.2454  Independence Day (ID4) (1996)\n",
      "\n",
      "*** Feature 9 ***\n",
      "  Movies with highest feature value\n",
      "    +0.2614  Jingle All the Way (1996)\n",
      "    +0.2485  My Best Friend's Wedding (1997)\n",
      "    +0.2461  Beavis and Butt-head Do America (1996)\n",
      "    +0.2378  From Dusk Till Dawn (1996)\n",
      "    +0.2250  Adventures of Priscilla, Queen of the Desert, The (1994)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.2644  Birdcage, The (1996)\n",
      "    -0.2494  Mighty Aphrodite (1995)\n",
      "    -0.2390  Everyone Says I Love You (1996)\n",
      "    -0.2308  Lost Highway (1997)\n",
      "    -0.2154  Benny & Joon (1993)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "features_to_examine = np.arange(0,10)\n",
    "\n",
    "for feature in features_to_examine:\n",
    "\n",
    "    feature_vals = V[:,feature]\n",
    "    \n",
    "    print ('*** Feature %d ***' % (feature))\n",
    "    print ('  Movies with highest feature value')\n",
    "    for i in get_highest(feature_vals)[0:k]:\n",
    "        print ('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print ('')\n",
    "    \n",
    "    print ('  Movies with lowest feature value')\n",
    "    for i in get_lowest(feature_vals)[0:k]:\n",
    "        print ('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print ('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nbpresent": {
   "slides": {
    "05dbf5c6-7ed4-44ff-96f5-22c560339a47": {
     "id": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "prev": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "regions": {
      "358609c2-5fc6-4b0e-b715-31776580497e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "48faf9e3-be4a-4ec4-888e-8ead4e2c67c5",
        "part": "whole"
       },
       "id": "358609c2-5fc6-4b0e-b715-31776580497e"
      }
     }
    },
    "1d9a4715-a031-4de3-8d97-d9e6066a461a": {
     "id": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "prev": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "regions": {
      "614fb7ec-54e5-4de3-bea3-88bec20b51e5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597ff142-4663-4ddb-bc6f-7b71e1127cc0",
        "part": "whole"
       },
       "id": "614fb7ec-54e5-4de3-bea3-88bec20b51e5"
      }
     }
    },
    "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c": {
     "id": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "prev": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "regions": {
      "36d74c3a-a835-4358-8199-45dbc6d3cbef": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c743c2d0-2dc4-4101-881c-01053255f632",
        "part": "whole"
       },
       "id": "36d74c3a-a835-4358-8199-45dbc6d3cbef"
      }
     }
    },
    "31877341-3b03-4601-8c41-3eb99ba92ab1": {
     "id": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "prev": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "regions": {
      "80e23835-4849-412a-8a53-23214ed34dd4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "705be6bb-9f8a-4d0f-804b-3c69c1a65bc9",
        "part": "whole"
       },
       "id": "80e23835-4849-412a-8a53-23214ed34dd4"
      }
     }
    },
    "42565e08-7bed-422d-a675-eb7334ca0ab5": {
     "id": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "prev": null,
     "regions": {
      "156465b7-096d-45d2-8bcf-7b00a992a68b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bd219f5b-9c65-4402-94f0-5e1933cc040f",
        "part": "whole"
       },
       "id": "156465b7-096d-45d2-8bcf-7b00a992a68b"
      }
     }
    },
    "60b8b15e-5b75-4c66-906d-f1d5ac44c63b": {
     "id": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "prev": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "regions": {
      "66cbb4cc-e38d-43e5-bff5-56c0c06fb651": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "496c99a6-522e-4637-aeda-aed1d27ea1a5",
        "part": "whole"
       },
       "id": "66cbb4cc-e38d-43e5-bff5-56c0c06fb651"
      }
     }
    },
    "68f4c6fe-5f2d-452d-835c-e3b7454d6b47": {
     "id": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "prev": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "regions": {
      "a5b4dede-9c3b-41d5-a601-171e4252eec5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "33f22eff-c565-4acc-bd8d-5d40678cb1e5",
        "part": "whole"
       },
       "id": "a5b4dede-9c3b-41d5-a601-171e4252eec5"
      }
     }
    },
    "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc": {
     "id": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "prev": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "regions": {
      "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "417fa0e4-6c70-4b9f-a42c-876215db961d",
        "part": "whole"
       },
       "id": "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7"
      }
     }
    },
    "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c": {
     "id": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "prev": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "regions": {
      "815ef0da-e3b6-488a-ac14-d837eecd3350": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534",
        "part": "whole"
       },
       "id": "815ef0da-e3b6-488a-ac14-d837eecd3350"
      }
     }
    },
    "99838ed2-6577-4917-a98b-5b45dbaff5b7": {
     "id": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "prev": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "regions": {
      "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2563258b-b1cb-45a3-baea-d0a9916e9f3a",
        "part": "whole"
       },
       "id": "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253"
      }
     }
    },
    "b75ebba2-4536-45b6-b14d-734821fc6db5": {
     "id": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "prev": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "regions": {
      "5b3123b6-b849-478a-b415-01dc4c7b8ddd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e6383de-b56e-4b0c-9173-05600260e586",
        "part": "whole"
       },
       "id": "5b3123b6-b849-478a-b415-01dc4c7b8ddd"
      }
     }
    },
    "ba5277be-2e8f-42a4-b899-2eb098d503e2": {
     "id": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "prev": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "regions": {
      "6672c882-0f15-431e-94d2-a39fd1c95dec": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa",
        "part": "whole"
       },
       "id": "6672c882-0f15-431e-94d2-a39fd1c95dec"
      }
     }
    },
    "c3f0d508-e7d2-45a1-9b29-91275df5c422": {
     "id": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "prev": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "regions": {
      "73d6c89e-93a2-47e7-ba8b-7dcd08353421": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8d3aa776-2611-48aa-b921-84ff8f528fdf",
        "part": "whole"
       },
       "id": "73d6c89e-93a2-47e7-ba8b-7dcd08353421"
      }
     }
    },
    "ca0eefa6-4215-4a13-96d3-ac4d59f36016": {
     "id": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "prev": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "regions": {
      "89f3061f-b00c-48f3-8862-9285b3370f5f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46a5a100-4e08-43e9-a313-ea1a0f06d149",
        "part": "whole"
       },
       "id": "89f3061f-b00c-48f3-8862-9285b3370f5f"
      }
     }
    },
    "d5c7ab89-c212-42a0-9613-2ecac8650d14": {
     "id": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "prev": "e1542729-bc97-495f-ac40-08ddb992f600",
     "regions": {
      "6b68aff0-cfbb-48a8-86fb-7a70448e8536": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f68ec3c-1530-4569-abd9-306b981a638b",
        "part": "whole"
       },
       "id": "6b68aff0-cfbb-48a8-86fb-7a70448e8536"
      }
     }
    },
    "e1542729-bc97-495f-ac40-08ddb992f600": {
     "id": "e1542729-bc97-495f-ac40-08ddb992f600",
     "prev": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "regions": {
      "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad3301d3-5e9b-4f82-8180-9410aa5fd885",
        "part": "whole"
       },
       "id": "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d"
      }
     }
    },
    "efe59041-9754-46cd-9a6f-a04eb76ccbbf": {
     "id": "efe59041-9754-46cd-9a6f-a04eb76ccbbf",
     "prev": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "regions": {
      "7c0bb904-8702-44bd-b57b-75e61e7a5a80": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "75676a65-f58b-4f20-b4a0-1cf8f1156d71",
        "part": "whole"
       },
       "id": "7c0bb904-8702-44bd-b57b-75e61e7a5a80"
      }
     }
    },
    "f0743c29-abc3-44be-87d6-dd1d5510322d": {
     "id": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "prev": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "regions": {
      "b058597c-5656-42c4-ae9e-74e567a11d40": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c",
        "part": "whole"
       },
       "id": "b058597c-5656-42c4-ae9e-74e567a11d40"
      }
     }
    },
    "f2a530ec-9ccc-485b-b61b-a99a778bbcba": {
     "id": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "prev": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "regions": {
      "3f7d423c-0b12-4667-886f-b8c5a8b455de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25aa92a1-20c9-4206-9133-ab31f96cb321",
        "part": "whole"
       },
       "id": "3f7d423c-0b12-4667-886f-b8c5a8b455de"
      }
     }
    },
    "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25": {
     "id": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "prev": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "regions": {
      "66fe2eda-b793-476d-989b-7eeca28e1890": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9c3800be-12ec-43a7-b24a-8cf543daf831",
        "part": "whole"
       },
       "id": "66fe2eda-b793-476d-989b-7eeca28e1890"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
