{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE TO FUTURE SELF\n",
    "\n",
    "This notebook needs some reorganizing to better steer students toward *stochastic gradient descent* and to simplify notation in the problem setup. The double subscripts in the main body below a incredibly confusing to students. \n",
    "\n",
    "\n",
    "Cost function with regularization\n",
    "\n",
    "\n",
    "$$J(i, j, r) = \\frac{1}{2}(\\mathbf{u}_i^T \\mathbf{v}_j - r)^2 + \\frac{\\lambda}{2}\\| \\mathbf{u}_i\\|^2 + \\|\\mathbf{v}_j\\|^2$$\n",
    "\n",
    "Partial derivatives\n",
    "\n",
    "$$\\begin{aligned}\\frac{\\partial}{\\partial \\mathbf{u}_i} J(i, j, r) &= (\\mathbf{u}_i^T \\mathbf{v}_j - r ) \\mathbf{v}_j + \\lambda \\mathbf{u}_i\\\\ \\frac{\\partial}{\\partial \\mathbf{v}_j} J(i, j, r) &= (\\mathbf{u}_i^T \\mathbf{v}_j - r ) \\mathbf{u}_i + \\lambda \\mathbf{v}_j \\end{aligned}$$\n",
    "\n",
    "\n",
    "Gradient descent update for one training example $(i, j, r)$:\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\\mathbf{u}_i &= \\mathbf{u}_i - \\alpha \\frac{\\partial}{\\partial \\mathbf{u}_i} J(i, j, r) \\\\ \\mathbf{v}_j &= \\mathbf{v}_j - \\alpha \\frac{\\partial}{\\partial \\mathbf{v}_i} J(i, j, r) \\end{aligned}$$\n",
    "\n",
    "\n",
    "Outline of gradient descent\n",
    "\n",
    "\n",
    "~~~~\n",
    "for each round // tens of rounds total \n",
    "    for k=1 to number of training examples  // 60K training examples\n",
    "\ti = train_user[k]\n",
    "\tj = train_movie[k]\n",
    "\tr = train_rating[k]\n",
    "\tmake gradient descent update for example (i, j, r)\n",
    "   \n",
    "   make predictions for entire training set and print rmse\n",
    "   make predictions for entire validation set and print rmse\n",
    "~~~~\n",
    "\n",
    "Outline of prediction function\n",
    "\n",
    "\n",
    "~~~~\n",
    "initialize predictions vector\n",
    "for k=1 to number of examples\n",
    "   i = user[k]\n",
    "   j = movie[k]\n",
    "   predictions[k] = prediction for user i on movie j\n",
    "~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd219f5b-9c65-4402-94f0-5e1933cc040f"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\renewcommand{\\b}{\\mathbf}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "$$\n",
    "\n",
    "\n",
    "# Movie Recommendations\n",
    "\n",
    "\n",
    "| user  | Moonlight | The Shape of Water   | Frozen | Moana     |\n",
    "|-------|-----------|----------------------|--------|-----------| \n",
    "|Alice  |   5       |          4           |    1   |           |\n",
    "|Bob    |           |          5           |        |    2      |\n",
    "|Carol  |           |                      |        |    5      |\n",
    "|David  |           |                      |    5   |    5      |\n",
    "|Eve    |   5       |          4           |        |           |\n",
    "\n",
    "\n",
    "What movie should I recommend to Bob?\n",
    "Will Carol like Frozen?\n",
    "\n",
    "**Goal**: Fill in entries of the \"rating matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "417fa0e4-6c70-4b9f-a42c-876215db961d"
    }
   },
   "source": [
    "# Problem Setup\n",
    "\n",
    "Let's formalize this as a machine learning problem. To make it concrete, let's load some data and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>Jungle2Jungle (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>Apocalypse Now (1979)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating                                title\n",
       "2070        0       242       1                 Jungle2Jungle (1997)\n",
       "2175        0        73       1  Faster Pussycat! Kill! Kill! (1965)\n",
       "984         0       101       2               Aristocats, The (1970)\n",
       "2400        0       236       2                 Jerry Maguire (1996)\n",
       "4364        0       179       3                Apocalypse Now (1979)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import scipy.io\n",
    "\n",
    "# Load train and test data\n",
    "data = scipy.io.loadmat('movies.mat')\n",
    "\n",
    "titles = [t[0] for t in data['movieData']['title'][0,0].ravel()]\n",
    "\n",
    "for x,y in data.items():\n",
    "    if isinstance(y, (np.ndarray)) and len(y)==1:\n",
    "        data[x] = np.asscalar(y)\n",
    "    elif isinstance(y, (np.ndarray)):\n",
    "        data[x] = y.ravel()\n",
    "\n",
    "nUsers    = data['nUsers']\n",
    "nMovies   = data['nMovies']\n",
    "userData  = data['userData']\n",
    "movieData = data['movieData']\n",
    "\n",
    "train_user   = data['train_user']-1   # matlab 1-index correction\n",
    "train_movie  = data['train_movie']-1  # matlab 1-index correction\n",
    "train_rating = data['train_rating']\n",
    "\n",
    "valid_user   = data['valid_user']-1   # matlab 1-index correction\n",
    "valid_movie  = data['valid_movie']-1  # matlab 1-index correction\n",
    "valid_rating = data['valid_rating']\n",
    "\n",
    "test_user    = data['test_user']-1    # matlab 1-index correction\n",
    "test_movie   = data['test_movie']-1   # matlab 1-index correction\n",
    "\n",
    "\n",
    "# Create a pandas data frame for training data to facilitate\n",
    "# visualization and inspection\n",
    "\n",
    "train_title = [titles[i] for i in train_movie]\n",
    "\n",
    "train_data = pd.DataFrame(data = {'user_id' : train_user, \n",
    "                                  'movie_id' : train_movie,\n",
    "                                  'rating' : train_rating,\n",
    "                                  'title': train_title}, \n",
    "                         columns = ['user_id', 'movie_id', 'rating', 'title'])\n",
    "\n",
    "# subsample to 5000 rows to more easily see a small sampling of ratings for each user\n",
    "train_data = train_data[:5000]\n",
    "\n",
    "# sort by user\n",
    "train_data = train_data.sort_values(by=['user_id', 'rating'])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534"
    }
   },
   "source": [
    "## Training Data\n",
    "As we can see, the training data presents observed entries of the \"ratings\" matrix as list of triples $(i_k, j_k, r_k)$ where\n",
    "\n",
    "* $i_k$ is the user index of $k$th rating\n",
    "* $j_k$ is the movie index of $k$th rating\n",
    "* $r_k$ is the value of $k$th rating (1-5)\n",
    "\n",
    "In our code we will store the entries of the tuples in three separate 1d arrays of the same length, so the $k$th rating is represented by the values ``train_user[k]``, ``train_movie[k]``, and ``train_rating[k]``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "33f22eff-c565-4acc-bd8d-5d40678cb1e5"
    }
   },
   "source": [
    "## Problem Formulation\n",
    "\n",
    "Now, let's formulate the problem mathematically. Suppose there are $m$ users and $n$ movies. \n",
    "Let $R$ be the $m \\times n$ \"rating\" matrix, where $R_{ij}$ is the (possibly unknown) rating for user $i$ on movie $j$. \n",
    "\n",
    "Our training data gives us some of the entries of the rating matrix. Our goal\n",
    "is to learn a parametric model to predict entries that we don't observe.\n",
    "\n",
    "#### But Where are the Features?\n",
    "\n",
    "What sort of predictive model can we use for entries of $R$? \n",
    "\n",
    "In past learning problems we had *feature vectors* and we learned *weight vectors* to make predictions (using dot products). \n",
    "\n",
    "Now we do not have feature vectors. What should we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ad3301d3-5e9b-4f82-8180-9410aa5fd885"
    }
   },
   "source": [
    "## Matrix Factorization Model\n",
    "\n",
    "Our solution is to **learn weight vectors for both users and movies**. \n",
    "\n",
    "Let $\\u_i \\in \\R^d$ be the weight vector for use $i$ and $\\v_j \\in \\R^d$ be the weight vector for movie $j$. Then we can predict the rating for user $i$ on movie $j$ as:\n",
    "\n",
    "$$\n",
    "H_{ij} =\\u_i^T \\v_j\n",
    "$$\n",
    "\n",
    "Our goal is to learn weight vectors for every user and movie so that $R_{ij} \\approx H_{ij}$ for those entries of the rating matrix that we observe.\n",
    "\n",
    "**Problem statement**: \n",
    "Given observed entries of the rating matrix presented as triples $(i_k, j_k, r_k)$ for $k=1, \\ldots, n_{\\text{train}}$, find weight vectors $\\mathbf{u_i}$ for each user $i$ and $\\mathbf{v}_j$ for each movie $j$ such that:\n",
    "$$\n",
    "r_k \\approx \\mathbf{u_{i_k}}^T \\mathbf{v_{j_k}}, \\quad k=1, 2, \\ldots, n_{\\text{train}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f68ec3c-1530-4569-abd9-306b981a638b"
    }
   },
   "source": [
    "## Why is This Called Matrix Factorization?\n",
    "\n",
    "* Place the user weight vectors $\\u_i$ into the rows of a matrix\n",
    "  $U$ and the movie feature vectors $\\v_j$ into\n",
    "  the rows of a matrix $V$\n",
    "\n",
    "    $$ \n",
    "    \\newcommand{\\line}{-}\n",
    "    U =\n",
    "        \\begin{bmatrix}\n",
    "            \\line \\u_1^T \\line \\\\\n",
    "            \\line \\u_2^T \\line \\\\\n",
    "            \\ldots \\\\\n",
    "            \\line \\u_m^T \\line \\\\\n",
    "        \\end{bmatrix} \\in \\R^{m \\times d}\n",
    "    \\qquad\n",
    "    V =\n",
    "        \\begin{bmatrix}\n",
    "            \\line \\v_1^T \\line \\\\\n",
    "            \\line \\v_2^T \\line \\\\\n",
    "            \\ldots \\\\\n",
    "            \\line \\v_n^T \\line \\\\\n",
    "        \\end{bmatrix} \\in \\R^{n \\times d}\n",
    "    $$\n",
    "\n",
    "* Consider the product $U V^T$:\n",
    "\n",
    "    $$\n",
    "    \\boxed{\n",
    "        \\begin{array}{c}\n",
    "            \\\\\n",
    "            U \\\\\n",
    "            \\\\\n",
    "        \\end{array}\n",
    "        }\n",
    "    \\boxed{\n",
    "        \\begin{array}{c}\n",
    "            \\ \\ \\ V^T \\ \\ \\ \n",
    "        \\end{array}\n",
    "        }\n",
    "    $$\n",
    "  \n",
    "* It is easy to check that $(i,j)$ entry of $UV^T$ is equal to $\\u_i^T\n",
    "  \\v_j$, which is our prediction for the $(i,j)$ entry of $R$\n",
    "\n",
    "* In other words, our model is that $R \\approx U V^T$ (a **factorization**\n",
    "  of $R$)\n",
    "\n",
    "* We choose $U$ and $V$ to get good predictions for those entries of\n",
    "  $R$ that we can observe. As long as we don't overfit, this gives us\n",
    "  power to generalize to entries we don't observe\n",
    "  \n",
    "* The \"hidden dimension\" $d$ (the length of each weight vector) is a hyperparameter\n",
    "  that must be tuned with hold-out data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c743c2d0-2dc4-4101-881c-01053255f632"
    }
   },
   "source": [
    "## Your Job: Solve the Learning Problem \n",
    "\n",
    "* Formulate a squared error cost function corresponding to the problem statement above.\n",
    "* Add regularization for *every* user weight vector $\\u_i$ and movie weight vector $\\v_j$ to get a regularized cost function\n",
    "* Write down the partial derivatives of your regularized cost function with\n",
    "  respect to the entries of $\\u_i$ and $\\v_j$\n",
    "* Plug the partial derivatives into stochastic gradient descent (SGD)\n",
    "  and write down the update rule\n",
    "* Implement SGD\n",
    "* Tune parameters (e.g., dimension $d$, regularization parameter) get good performance on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "25aa92a1-20c9-4206-9133-ab31f96cb321"
    }
   },
   "source": [
    "## Logistics\n",
    "\n",
    "* Work with a partner \n",
    "* Any resources allowed: talk to me, other groups, etc.\n",
    "* Submit predictions on test set --- you can submit one set of predictions per pair, or submit individually if you want. Work it out with your partner. \n",
    "* Evaluation: root-mean squared error (RMSE) on test set\n",
    "\n",
    "    $$ \\text{RMSE} = \\sqrt{\\frac{1}{n_{\\text{test}}}\\sum_{(i,j) \\in \\text{test set}} (H_{ij} - R_{ij})^2}$$\n",
    "\n",
    "* Worth 1/2 of regular homework\n",
    "\n",
    "| RMSE   |  grade  |\n",
    "|--------|---------|\n",
    "|<= 1.0  |  80%    |\n",
    "|<= 0.97 |  90%    |\n",
    "|<= 0.95 |   95%   |\n",
    "|<= 0.94 |  100%   ||\n",
    "\n",
    "* Due date announced later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "597ff142-4663-4ddb-bc6f-7b71e1127cc0"
    }
   },
   "source": [
    "## (Review on your own) Model Extension: Add Biases\n",
    "\n",
    "To get really great performance, consider this extended model for a predicted rating:\n",
    "\n",
    "$$\n",
    "H_{ij} = \\mu + a_i + b_j + \\u_i^T \\v_j\n",
    "$$\n",
    "\n",
    "This adds several terms to the prediction for user $i$ on movie $j$:\n",
    "\n",
    "* $\\mu$ is an overall baseline rating. For example, the overall average rating of all users\n",
    "  on all movies may be $\\mu = 3.3$\n",
    "  \n",
    "* $a_i$ is a user-specific adjustment or \"bias\". For example, perhaps Alice\n",
    "  really loves movies and gives them all high ratings. Then, her bias \n",
    "  might be $a_i = +0.4$. But Bob is hard to please, so his bias is $a_i = -0.7$.\n",
    "  \n",
    "* $b_j$ is a movie-specific bias. For example, perhaps Inside Out is universally\n",
    "  loved, so its bias is $b_j = +0.7$. A really bad movie would have a negative bias.\n",
    "\n",
    "The set of parameters of this model includes:\n",
    "\n",
    "* $\\mu$ \n",
    "* $a_i$, $i=1,\\ldots, m$\n",
    "* $b_j$, $j=1,\\ldots, n$\n",
    "* $\\u_i \\in \\R^d$, $i=1,\\ldots, m$\n",
    "* $\\v_j \\in \\R^d$, $j=1,\\ldots, n$\n",
    "\n",
    "To learn these parameters, derive partial derivatives of the regularized\n",
    "cost function with respect to *all* of the above parameters, and update\n",
    "them all within your stochastic gradient descent loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "[Matrix Factorization Techniques for Recommender\n",
    "Systems](http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf)\n",
    "by Yehuda Koren, Robert Bell and Chris Volinsky\n",
    "\n",
    "* Authors were on the winning team of Netflix prize\n",
    "\n",
    "* Paper includes algorithms---but beware different notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Familiarize Yourself With Variables\n",
    "\n",
    "Here are the variables we populated while loading the data above --- make sure you run that cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Metadata\n",
    "#     \n",
    "#     nUsers     # of users\n",
    "#     nMovies    # of movies\n",
    "#     titles     list of movie titles\n",
    "#\n",
    "#\n",
    "# 2) Training data (60K ratings). This consists of three 1d arrays, \n",
    "#    each of length 60K:\n",
    "#\n",
    "#      train_user, train_movie, train_rating\n",
    "#\n",
    "#    The entries specify the ratings:\n",
    "#   \n",
    "#      train_user[k]    user index  of kth rating\n",
    "#      train_movie[k]   movie index of kth rating\n",
    "#      train_rating[k]  value (1-5) of kth rating\n",
    "#\n",
    "# 2) Validation data (20K ratings). Three vectors of length 20K:\n",
    "#\n",
    "#      valid_user, valid_movie, valid_rating\n",
    "#   \n",
    "#    Use this to evaluate your model and tune parameters.\n",
    "#    \n",
    "# 3) Test set (20K user-movie pairs without ratings):\n",
    "#\n",
    "#      test_user, test_movie\n",
    "#\n",
    "#    You will create predictions for these pairs and submit them for \n",
    "#    grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Look at the Prediction Method\n",
    "\n",
    "To make things concrete, first take a look at the prediction method below. This is just a stub for now that returns the same value ``mu`` for every prediction. Later you will update this to make predictions given the weight vectors and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbpresent": {
     "id": "46a5a100-4e08-43e9-a313-ea1a0f06d149"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  6.,   4.,  12., -16.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(h, r):\n",
    "    resid = h - r\n",
    "    cost = np.sqrt(np.mean(resid**2))\n",
    "    return cost\n",
    "\n",
    "def predict(mu, user, movie, U, V, a=None, b=None):\n",
    "    '''\n",
    "    PREDICT Make predictions for user/movie pairs\n",
    "    Inputs: \n",
    "      model parameters\n",
    "      user               vector of users\n",
    "      movie              vector of movies\n",
    "    \n",
    "    Output:\n",
    "      predictions        vector of predictions\n",
    "    '''    \n",
    "    \n",
    "    # This is a stub that predicts the mean rating for all user-movie pairs\n",
    "    # Replace with your code.\n",
    "    \n",
    "    # np.dot(U, V.T)  shape (m, n)\n",
    "    # a has shape (m, )\n",
    "    # b has shape (n, )\n",
    "    # mu has shape (1,)\n",
    "    \n",
    "    H = mu + a.reshape(-1, 1) + b.reshape(1, -1) + np.dot(U, V.T)   \n",
    "    print(H.shape)\n",
    "\n",
    "    L = len(user)\n",
    "    predictions = np.zeros(L)\n",
    "    predictions[:] = H[user, movie]\n",
    "    \n",
    "    # restrict predictions to be between 1 and 5?  or will this slow down learning?\n",
    "#     predictions[predictions > 5] = 5\n",
    "#     predictions[predictions < 1] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# a little test case: \n",
    "#  4 users\n",
    "#  5 movies\n",
    "#  d=3\n",
    "\n",
    "d = 3\n",
    "mu = 3\n",
    "a = np.array([1, -12, -20, 0])\n",
    "b = np.array([5, 4, 3, 2, 1])\n",
    "U = np.array([[1, 1, 1],\n",
    "              [2, 2, 2],\n",
    "              [0.5, 2, 1],\n",
    "              [3, 1, 0.33]])\n",
    "V = np.array([[1, 1, 1],\n",
    "              [2, 2, 2],\n",
    "              [3, 3, 3],\n",
    "              [0, 0, 0],\n",
    "              [-2, 0, 1]\n",
    "             ])\n",
    "\n",
    "# user-movie pairs\n",
    "users = np.array([0, 0, 1, 2])\n",
    "movies = np.array([3, 4, 2, 4])\n",
    "\n",
    "x = predict(mu, users, movies, U, V, a, b)\n",
    "# user i - movie j : mu + u_i + b_j + H_ij\n",
    "# user 0 - movie 3 : 3  +   1 +   2 +    0 = 6\n",
    "# user 0 - movie 4 : 3  +   1 +   1 +   -1 = 4\n",
    "# user 1 - movie 2 : 3  + -12 +   3 +   18 = 12\n",
    "# user 2 - movie 4 : 3  + -20 +   1 +    0 = -16\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Learning and Validation\n",
    "\n",
    "Write code here to do the learning and validation. Stubs are provided. Make sure you derive the partial derivatives on paper before you try to code them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., 1.],\n",
       "       [1., 1., 2., 5.],\n",
       "       [1., 1., 1., 4.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mf\n",
    "R = np.array([[0, 1, 2, 0],\n",
    "          [1, 1, 2, 5],\n",
    "          [1, 1, 0, 4],\n",
    "          [0, 0, 0, 0],\n",
    "         ])\n",
    "np.maximum(np.ones(R.shape), R)\n",
    "# help(np.max)\n",
    "# T = R.sum(axis=1) / (R > 0).sum(axis=1)\n",
    "# (R > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL e_in=1.850\n",
      "round=1, e_in=1.268\n",
      "round=2, e_in=1.036\n",
      "round=3, e_in=0.996\n",
      "round=4, e_in=0.985\n",
      "round=5, e_in=0.973\n",
      "round=6, e_in=0.972\n",
      "round=7, e_in=0.969\n",
      "round=8, e_in=0.956\n",
      "round=9, e_in=0.950\n",
      "round=10, e_in=0.946\n",
      "round=11, e_in=0.941\n",
      "round=12, e_in=0.928\n",
      "round=13, e_in=0.919\n",
      "round=14, e_in=0.912\n",
      "round=15, e_in=0.895\n",
      "round=16, e_in=0.882\n",
      "round=17, e_in=0.875\n",
      "round=18, e_in=0.867\n",
      "round=19, e_in=0.854\n",
      "round=20, e_in=0.845\n",
      "round=21, e_in=0.834\n",
      "round=22, e_in=0.820\n",
      "round=23, e_in=0.813\n",
      "round=24, e_in=0.799\n",
      "round=25, e_in=0.790\n",
      "round=26, e_in=0.779\n",
      "round=27, e_in=0.778\n",
      "round=28, e_in=0.764\n",
      "round=29, e_in=0.761\n",
      "round=30, e_in=0.752\n",
      "round=31, e_in=0.745\n",
      "round=32, e_in=0.743\n",
      "round=33, e_in=0.729\n",
      "round=34, e_in=0.732\n",
      "round=35, e_in=0.724\n",
      "round=36, e_in=0.722\n",
      "round=37, e_in=0.717\n",
      "round=38, e_in=0.716\n",
      "round=39, e_in=0.710\n",
      "round=40, e_in=0.706\n",
      "round=41, e_in=0.705\n",
      "round=42, e_in=0.699\n",
      "round=43, e_in=0.700\n",
      "round=44, e_in=0.697\n",
      "round=45, e_in=0.695\n",
      "round=46, e_in=0.688\n",
      "round=47, e_in=0.689\n",
      "round=48, e_in=0.691\n",
      "round=49, e_in=0.691\n",
      "round=50, e_in=0.687\n",
      "train_rmse=0.687, valid_rmse=0.994\n"
     ]
    }
   ],
   "source": [
    "from mf import predict\n",
    "nDims = 20\n",
    "lamb = 0.001\n",
    "d, lamb = param_search(train_user, train_movie, train_rating, valid_user, valid_movie, valid_rating, nUsers, nMovies)\n",
    "\n",
    "results, mu, a, b, U, V = mf.fit(train_user, train_movie, train_rating, nUsers, nMovies, d, lamb)\n",
    "train_predictions = predict(mu, train_user, train_movie, U, V, a, b)\n",
    "valid_predictions = predict(mu, valid_user, valid_movie, U, V, a, b)\n",
    "\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "\n",
    "print('train_rmse=%.3f, valid_rmse=%.3f' % (train_rmse, valid_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbpresent": {
     "id": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a445e75cb414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#  pairs. Update it to take more parameters and make real predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_movie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mvalid_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_movie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Tunable parameters (you will add more)\n",
    "############################################\n",
    "\n",
    "nDims = 10\n",
    "\n",
    "############################################\n",
    "# Initialize parameters\n",
    "############################################\n",
    "\n",
    "mu = np.mean(train_rating)\n",
    "a  = np.zeros(nUsers)\n",
    "b  = np.zeros(nMovies)\n",
    "U  = np.random.randn(nUsers, nDims)  *.01 # User weights\n",
    "V  = np.random.randn(nMovies, nDims) *.01 # Movie features\n",
    "\n",
    "############################################\n",
    "# Training and validation\n",
    "############################################\n",
    "\n",
    "# TODO: write code to train model and evaluate performance on validation set\n",
    "#\n",
    "#  predict() is a stub that predicts the overall mean for all user-movie\n",
    "#  pairs. Update it to take more parameters and make real predictions.\n",
    "\n",
    "train_predictions = predict(mu, train_user, train_movie, U, V, a, b)\n",
    "valid_predictions = predict(mu, valid_user, valid_movie, U, V, a, b)\n",
    "\n",
    "train_rmse = rmse(train_predictions, train_rating)\n",
    "valid_rmse = rmse(valid_predictions, valid_rating)\n",
    "\n",
    "print('train_rmse=%.3f, valid_rmse=%.3f' % (train_rmse, valid_rmse))\n",
    "\n",
    "############################################\n",
    "# Testing\n",
    "############################################\n",
    "\n",
    "# Make and save predictions for test set\n",
    "test_predictions = predict(mu, test_user, test_movie, U, V, a, b)\n",
    "np.savetxt('test_predictions.txt', test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Material: Inspect Predictions for Different Users\n",
    "\n",
    "After you have learned a good model, you may wish to interpret what it has learned. We can do this by looking at the most positive and most negative predictions for different users\n",
    "(or the movies that are bumped up or down from the baseline the most).\n",
    "\n",
    "Read and run the code below to see if you can understand the predictions. (Note: the predictions won't make sense until you have learned a good model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "nbpresent": {
     "id": "9c3800be-12ec-43a7-b24a-8cf543daf831"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User 0 ***\n",
      "  Top movies\n",
      "    +0.0582  Butcher Boy, The (1998)\n",
      "    +0.0424  Line King: Al Hirschfeld, The (1996)\n",
      "    +0.0380  Land and Freedom (Tierra y libertad) (1995)\n",
      "    +0.0297  Santa with Muscles (1996)\n",
      "    +0.0289  Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "    +0.0272  Dadetown (1995)\n",
      "    +0.0271  To Cross the Rubicon (1991)\n",
      "    +0.0240  Angela (1995)\n",
      "\n",
      "  Bottom movies\n",
      "    -9.2499  Air Force One (1997)\n",
      "    -8.8747  White Squall (1996)\n",
      "    -8.8345  Conspiracy Theory (1997)\n",
      "    -8.8228  Money Talks (1997)\n",
      "    -8.7237  George of the Jungle (1997)\n",
      "    -8.5893  Beautician and the Beast, The (1997)\n",
      "    -8.5349  Jungle2Jungle (1997)\n",
      "    -8.5317  Santa Clause, The (1994)\n",
      "\n",
      "*** User 1 ***\n",
      "  Top movies\n",
      "    +0.0641  Butcher Boy, The (1998)\n",
      "    +0.0440  Dadetown (1995)\n",
      "    +0.0420  To Cross the Rubicon (1991)\n",
      "    +0.0420  Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "    +0.0391  Big One, The (1997)\n",
      "    +0.0334  I, Worst of All (Yo, la peor de todas) (1990)\n",
      "    +0.0324  Girls Town (1996)\n",
      "    +0.0270  Line King: Al Hirschfeld, The (1996)\n",
      "\n",
      "  Bottom movies\n",
      "    -8.9238  Scream 2 (1997)\n",
      "    -8.8169  Volcano (1997)\n",
      "    -8.8097  Event Horizon (1997)\n",
      "    -8.6476  Liar Liar (1997)\n",
      "    -8.5887  Congo (1995)\n",
      "    -8.5867  Homeward Bound II: Lost in San Francisco (1996)\n",
      "    -8.4729  Reality Bites (1994)\n",
      "    -8.4684  Jungle2Jungle (1997)\n",
      "\n",
      "*** User 2 ***\n",
      "  Top movies\n",
      "    +0.0559  Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "    +0.0511  Dadetown (1995)\n",
      "    +0.0508  Butcher Boy, The (1998)\n",
      "    +0.0435  Daniel Defoe's Robinson Crusoe (1996)\n",
      "    +0.0403  Nothing Personal (1995)\n",
      "    +0.0282  Land and Freedom (Tierra y libertad) (1995)\n",
      "    +0.0281  Good Morning (1971)\n",
      "    +0.0277  August (1996)\n",
      "\n",
      "  Bottom movies\n",
      "    -9.8960  Evita (1996)\n",
      "    -9.3212  Money Talks (1997)\n",
      "    -8.9476  Up Close and Personal (1996)\n",
      "    -8.9376  Steel (1997)\n",
      "    -8.9013  Mirror Has Two Faces, The (1996)\n",
      "    -8.8196  Kids in the Hall: Brain Candy (1996)\n",
      "    -8.7775  Cabin Boy (1994)\n",
      "    -8.7635  Soul Food (1997)\n",
      "\n",
      "*** User 3 ***\n",
      "  Top movies\n",
      "    +0.0775  Butcher Boy, The (1998)\n",
      "    +0.0426  Dadetown (1995)\n",
      "    +0.0365  Pushing Hands (1992)\n",
      "    +0.0361  Nothing Personal (1995)\n",
      "    +0.0344  Daniel Defoe's Robinson Crusoe (1996)\n",
      "    +0.0314  Girls Town (1996)\n",
      "    +0.0303  I, Worst of All (Yo, la peor de todas) (1990)\n",
      "    +0.0263  Daens (1992)\n",
      "\n",
      "  Bottom movies\n",
      "    -8.9067  Saint, The (1997)\n",
      "    -8.7307  Volcano (1997)\n",
      "    -8.5090  American President, The (1995)\n",
      "    -8.4963  Conspiracy Theory (1997)\n",
      "    -8.4909  Indian in the Cupboard, The (1995)\n",
      "    -8.4342  Phenomenon (1996)\n",
      "    -8.3906  Air Force One (1997)\n",
      "    -8.3902  Devil's Own, The (1997)\n",
      "\n",
      "*** User 4 ***\n",
      "  Top movies\n",
      "    +0.0776  Butcher Boy, The (1998)\n",
      "    +0.0400  Death in Brunswick (1991)\n",
      "    +0.0392  Dadetown (1995)\n",
      "    +0.0377  To Cross the Rubicon (1991)\n",
      "    +0.0363  Daniel Defoe's Robinson Crusoe (1996)\n",
      "    +0.0344  Hedd Wyn (1992)\n",
      "    +0.0338  Pushing Hands (1992)\n",
      "    +0.0332  I, Worst of All (Yo, la peor de todas) (1990)\n",
      "\n",
      "  Bottom movies\n",
      "    -9.9758  I Know What You Did Last Summer (1997)\n",
      "    -9.9564  Piano, The (1993)\n",
      "    -9.6396  Homeward Bound II: Lost in San Francisco (1996)\n",
      "    -9.5952  Halloween: The Curse of Michael Myers (1995)\n",
      "    -9.5920  Liar Liar (1997)\n",
      "    -9.5898  Volcano (1997)\n",
      "    -9.4671  Nixon (1995)\n",
      "    -9.4528  Ice Storm, The (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_movies = range(nMovies)\n",
    "\n",
    "def get_lowest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    return most_negative\n",
    "\n",
    "def get_highest(vals):\n",
    "    most_negative = np.argsort(vals)\n",
    "    most_positive = most_negative[::-1]\n",
    "    return most_positive\n",
    "\n",
    "k = 8\n",
    "all_users = range(nUsers)\n",
    "users_to_examine = all_users[0:5]\n",
    "\n",
    "for user in users_to_examine:\n",
    "\n",
    "    # Changes from baseline movie predictions for this user\n",
    "    delta = np.dot(V, U[user,:])  \n",
    "\n",
    "    print('*** User %d ***' % (user))\n",
    "    print('  Top movies')\n",
    "    for i in get_highest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n",
    "    \n",
    "    print('  Bottom movies')\n",
    "    for i in get_lowest(delta)[0:k]:\n",
    "        print('    %+.4f  %s' % (delta[i], titles[i]))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "496c99a6-522e-4637-aeda-aed1d27ea1a5"
    }
   },
   "source": [
    "## More Bonus Material: Interpretation of Weight Vectors as Features\n",
    "\n",
    "* So far we have described both $\\u_i$ and $\\v_j$ as *weight vectors* (since we don't have any features of movies and users). But, it is possible to interpret one or both of these vectors as **learned features**. \n",
    "\n",
    "* For example, the first learned feature may discover a preference for comedy vs. drama. In this case:\n",
    "    * The user feature value $u_{i1}$ should be high if the user likes comedies and low if the user likes dramas better.\n",
    "    * The movie feature value $v_{j1}$ should be high if the movie is a comedy and low if it is a drama. \n",
    "    \n",
    "* Similarly, feature 2 might describe whether a movie is geared toward kids or adults\n",
    "\n",
    "* In practice, the feature interpretations often find recognizable patterns but are not quite so clean to describe as the two examples above.\n",
    "\n",
    "Run the code below to examine the movies with the highest and lowest feature values for some of the features in your learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "nbpresent": {
     "id": "8d3aa776-2611-48aa-b921-84ff8f528fdf"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature 0 ***\n",
      "  Movies with highest feature value\n",
      "    +1.5730  Leaving Las Vegas (1995)\n",
      "    +1.2363  Money Talks (1997)\n",
      "    +1.2106  Evita (1996)\n",
      "    +1.0522  Heavy Metal (1981)\n",
      "    +0.9360  Everyone Says I Love You (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.9163  Evil Dead II (1987)\n",
      "    -1.9049  Nightmare on Elm Street, A (1984)\n",
      "    -1.7751  Beavis and Butt-head Do America (1996)\n",
      "    -1.7505  Ed Wood (1994)\n",
      "    -1.6388  2001: A Space Odyssey (1968)\n",
      "\n",
      "*** Feature 1 ***\n",
      "  Movies with highest feature value\n",
      "    +1.6707  Assassins (1995)\n",
      "    +1.5086  In the Company of Men (1997)\n",
      "    +1.4782  Ref, The (1994)\n",
      "    +1.4312  Alien (1979)\n",
      "    +1.4275  Dragonheart (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -2.2506  English Patient, The (1996)\n",
      "    -1.8596  Piano, The (1993)\n",
      "    -1.5218  Nixon (1995)\n",
      "    -1.4595  Lost Highway (1997)\n",
      "    -1.3202  Pulp Fiction (1994)\n",
      "\n",
      "*** Feature 2 ***\n",
      "  Movies with highest feature value\n",
      "    +1.6926  Chasing Amy (1997)\n",
      "    +1.4223  Very Brady Sequel, A (1996)\n",
      "    +1.3304  Soul Food (1997)\n",
      "    +1.1635  Kids in the Hall: Brain Candy (1996)\n",
      "    +1.1543  Contact (1997)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.8372  Event Horizon (1997)\n",
      "    -1.8099  Dirty Dancing (1987)\n",
      "    -1.7131  Bean (1997)\n",
      "    -1.6277  Saint, The (1997)\n",
      "    -1.4936  Homeward Bound II: Lost in San Francisco (1996)\n",
      "\n",
      "*** Feature 3 ***\n",
      "  Movies with highest feature value\n",
      "    +1.1350  Seven Years in Tibet (1997)\n",
      "    +1.0113  Forrest Gump (1994)\n",
      "    +1.0103  In the Company of Men (1997)\n",
      "    +0.9869  English Patient, The (1996)\n",
      "    +0.9546  Amistad (1997)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.8159  Robin Hood: Men in Tights (1993)\n",
      "    -1.8023  Apostle, The (1997)\n",
      "    -1.7045  Four Rooms (1995)\n",
      "    -1.6959  Crow: City of Angels, The (1996)\n",
      "    -1.6894  Ace Ventura: Pet Detective (1994)\n",
      "\n",
      "*** Feature 4 ***\n",
      "  Movies with highest feature value\n",
      "    +0.7140  Grease (1978)\n",
      "    +0.4630  Black Sheep (1996)\n",
      "    +0.4546  Fast, Cheap & Out of Control (1997)\n",
      "    +0.4179  Screamers (1995)\n",
      "    +0.3375  Naked Gun 33 1/3: The Final Insult (1994)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -3.1136  Full Monty, The (1997)\n",
      "    -3.1049  In & Out (1997)\n",
      "    -3.0294  Everyone Says I Love You (1996)\n",
      "    -2.4040  Grosse Pointe Blank (1997)\n",
      "    -2.2601  Princess Bride, The (1987)\n",
      "\n",
      "*** Feature 5 ***\n",
      "  Movies with highest feature value\n",
      "    +3.6077  White Squall (1996)\n",
      "    +3.4810  Trainspotting (1996)\n",
      "    +3.4102  Scream (1996)\n",
      "    +3.4061  Long Kiss Goodnight, The (1996)\n",
      "    +3.3745  Piano, The (1993)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -0.0248  Butcher Boy, The (1998)\n",
      "    -0.0200  Land and Freedom (Tierra y libertad) (1995)\n",
      "    -0.0133  To Cross the Rubicon (1991)\n",
      "    -0.0132  Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "    -0.0121  Santa with Muscles (1996)\n",
      "\n",
      "*** Feature 6 ***\n",
      "  Movies with highest feature value\n",
      "    +1.9115  Crash (1996)\n",
      "    +1.2887  Boogie Nights (1997)\n",
      "    +1.0596  Event Horizon (1997)\n",
      "    +1.0539  Lost Highway (1997)\n",
      "    +1.0508  Natural Born Killers (1994)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.9790  Indian in the Cupboard, The (1995)\n",
      "    -1.7788  Field of Dreams (1989)\n",
      "    -1.7450  Kingpin (1996)\n",
      "    -1.6586  Gone with the Wind (1939)\n",
      "    -1.6426  It's a Wonderful Life (1946)\n",
      "\n",
      "*** Feature 7 ***\n",
      "  Movies with highest feature value\n",
      "    +1.1938  Contact (1997)\n",
      "    +1.1411  Fifth Element, The (1997)\n",
      "    +1.0959  Nightmare on Elm Street, A (1984)\n",
      "    +1.0581  Sound of Music, The (1965)\n",
      "    +1.0121  Evita (1996)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -2.0548  Kingpin (1996)\n",
      "    -2.0170  Very Brady Sequel, A (1996)\n",
      "    -1.7555  Full Monty, The (1997)\n",
      "    -1.6685  Boogie Nights (1997)\n",
      "    -1.6245  Supercop (1992)\n",
      "\n",
      "*** Feature 8 ***\n",
      "  Movies with highest feature value\n",
      "    +1.5412  Man Who Knew Too Little, The (1997)\n",
      "    +1.3813  Midnight in the Garden of Good and Evil (1997)\n",
      "    +1.3272  Everyone Says I Love You (1996)\n",
      "    +1.2315  Wings of Desire (1987)\n",
      "    +1.2291  Muriel's Wedding (1994)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -1.8801  Fifth Element, The (1997)\n",
      "    -1.8650  Omen, The (1976)\n",
      "    -1.7896  Scream (1996)\n",
      "    -1.7516  Gattaca (1997)\n",
      "    -1.7211  Scream 2 (1997)\n",
      "\n",
      "*** Feature 9 ***\n",
      "  Movies with highest feature value\n",
      "    +1.6618  Air Force One (1997)\n",
      "    +1.3937  Titanic (1997)\n",
      "    +1.3812  George of the Jungle (1997)\n",
      "    +1.3480  My Best Friend's Wedding (1997)\n",
      "    +1.3431  Conspiracy Theory (1997)\n",
      "\n",
      "  Movies with lowest feature value\n",
      "    -2.1195  Mighty Aphrodite (1995)\n",
      "    -1.9272  Conan the Barbarian (1981)\n",
      "    -1.8676  Big Night (1996)\n",
      "    -1.7091  Leaving Las Vegas (1995)\n",
      "    -1.6387  Jackie Brown (1997)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "features_to_examine = np.arange(0,10)\n",
    "\n",
    "for feature in features_to_examine:\n",
    "\n",
    "    feature_vals = V[:,feature]\n",
    "    \n",
    "    print ('*** Feature %d ***' % (feature))\n",
    "    print ('  Movies with highest feature value')\n",
    "    for i in get_highest(feature_vals)[0:k]:\n",
    "        print ('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print ('')\n",
    "    \n",
    "    print ('  Movies with lowest feature value')\n",
    "    for i in get_lowest(feature_vals)[0:k]:\n",
    "        print ('    %+.4f  %s' % (feature_vals[i], titles[i]))\n",
    "    print ('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {
    "05dbf5c6-7ed4-44ff-96f5-22c560339a47": {
     "id": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "prev": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "regions": {
      "358609c2-5fc6-4b0e-b715-31776580497e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "48faf9e3-be4a-4ec4-888e-8ead4e2c67c5",
        "part": "whole"
       },
       "id": "358609c2-5fc6-4b0e-b715-31776580497e"
      }
     }
    },
    "1d9a4715-a031-4de3-8d97-d9e6066a461a": {
     "id": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "prev": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "regions": {
      "614fb7ec-54e5-4de3-bea3-88bec20b51e5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597ff142-4663-4ddb-bc6f-7b71e1127cc0",
        "part": "whole"
       },
       "id": "614fb7ec-54e5-4de3-bea3-88bec20b51e5"
      }
     }
    },
    "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c": {
     "id": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "prev": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "regions": {
      "36d74c3a-a835-4358-8199-45dbc6d3cbef": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c743c2d0-2dc4-4101-881c-01053255f632",
        "part": "whole"
       },
       "id": "36d74c3a-a835-4358-8199-45dbc6d3cbef"
      }
     }
    },
    "31877341-3b03-4601-8c41-3eb99ba92ab1": {
     "id": "31877341-3b03-4601-8c41-3eb99ba92ab1",
     "prev": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "regions": {
      "80e23835-4849-412a-8a53-23214ed34dd4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "705be6bb-9f8a-4d0f-804b-3c69c1a65bc9",
        "part": "whole"
       },
       "id": "80e23835-4849-412a-8a53-23214ed34dd4"
      }
     }
    },
    "42565e08-7bed-422d-a675-eb7334ca0ab5": {
     "id": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "prev": null,
     "regions": {
      "156465b7-096d-45d2-8bcf-7b00a992a68b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bd219f5b-9c65-4402-94f0-5e1933cc040f",
        "part": "whole"
       },
       "id": "156465b7-096d-45d2-8bcf-7b00a992a68b"
      }
     }
    },
    "60b8b15e-5b75-4c66-906d-f1d5ac44c63b": {
     "id": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "prev": "1d9a4715-a031-4de3-8d97-d9e6066a461a",
     "regions": {
      "66cbb4cc-e38d-43e5-bff5-56c0c06fb651": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "496c99a6-522e-4637-aeda-aed1d27ea1a5",
        "part": "whole"
       },
       "id": "66cbb4cc-e38d-43e5-bff5-56c0c06fb651"
      }
     }
    },
    "68f4c6fe-5f2d-452d-835c-e3b7454d6b47": {
     "id": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "prev": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "regions": {
      "a5b4dede-9c3b-41d5-a601-171e4252eec5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "33f22eff-c565-4acc-bd8d-5d40678cb1e5",
        "part": "whole"
       },
       "id": "a5b4dede-9c3b-41d5-a601-171e4252eec5"
      }
     }
    },
    "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc": {
     "id": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "prev": "42565e08-7bed-422d-a675-eb7334ca0ab5",
     "regions": {
      "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "417fa0e4-6c70-4b9f-a42c-876215db961d",
        "part": "whole"
       },
       "id": "43bdf1a6-2a38-4ea8-8452-9f4de7c7b5e7"
      }
     }
    },
    "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c": {
     "id": "87e6cfef-5c0f-4d3c-bd82-2dd2612efc0c",
     "prev": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "regions": {
      "815ef0da-e3b6-488a-ac14-d837eecd3350": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d66fcd3-b9d3-49cf-a93c-0f4bdcfbf534",
        "part": "whole"
       },
       "id": "815ef0da-e3b6-488a-ac14-d837eecd3350"
      }
     }
    },
    "99838ed2-6577-4917-a98b-5b45dbaff5b7": {
     "id": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "prev": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "regions": {
      "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2563258b-b1cb-45a3-baea-d0a9916e9f3a",
        "part": "whole"
       },
       "id": "7fe37cdc-68ea-4184-ba0e-d0b1a2bc7253"
      }
     }
    },
    "b75ebba2-4536-45b6-b14d-734821fc6db5": {
     "id": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "prev": "05dbf5c6-7ed4-44ff-96f5-22c560339a47",
     "regions": {
      "5b3123b6-b849-478a-b415-01dc4c7b8ddd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e6383de-b56e-4b0c-9173-05600260e586",
        "part": "whole"
       },
       "id": "5b3123b6-b849-478a-b415-01dc4c7b8ddd"
      }
     }
    },
    "ba5277be-2e8f-42a4-b899-2eb098d503e2": {
     "id": "ba5277be-2e8f-42a4-b899-2eb098d503e2",
     "prev": "6a7c9ec6-ca33-4dcc-b565-a2393a88d2dc",
     "regions": {
      "6672c882-0f15-431e-94d2-a39fd1c95dec": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7121a063-dcd8-4ef3-9b68-fdeb4690a1aa",
        "part": "whole"
       },
       "id": "6672c882-0f15-431e-94d2-a39fd1c95dec"
      }
     }
    },
    "c3f0d508-e7d2-45a1-9b29-91275df5c422": {
     "id": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "prev": "60b8b15e-5b75-4c66-906d-f1d5ac44c63b",
     "regions": {
      "73d6c89e-93a2-47e7-ba8b-7dcd08353421": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8d3aa776-2611-48aa-b921-84ff8f528fdf",
        "part": "whole"
       },
       "id": "73d6c89e-93a2-47e7-ba8b-7dcd08353421"
      }
     }
    },
    "ca0eefa6-4215-4a13-96d3-ac4d59f36016": {
     "id": "ca0eefa6-4215-4a13-96d3-ac4d59f36016",
     "prev": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "regions": {
      "89f3061f-b00c-48f3-8862-9285b3370f5f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46a5a100-4e08-43e9-a313-ea1a0f06d149",
        "part": "whole"
       },
       "id": "89f3061f-b00c-48f3-8862-9285b3370f5f"
      }
     }
    },
    "d5c7ab89-c212-42a0-9613-2ecac8650d14": {
     "id": "d5c7ab89-c212-42a0-9613-2ecac8650d14",
     "prev": "e1542729-bc97-495f-ac40-08ddb992f600",
     "regions": {
      "6b68aff0-cfbb-48a8-86fb-7a70448e8536": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f68ec3c-1530-4569-abd9-306b981a638b",
        "part": "whole"
       },
       "id": "6b68aff0-cfbb-48a8-86fb-7a70448e8536"
      }
     }
    },
    "e1542729-bc97-495f-ac40-08ddb992f600": {
     "id": "e1542729-bc97-495f-ac40-08ddb992f600",
     "prev": "68f4c6fe-5f2d-452d-835c-e3b7454d6b47",
     "regions": {
      "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad3301d3-5e9b-4f82-8180-9410aa5fd885",
        "part": "whole"
       },
       "id": "eb7f4a22-90e2-45ea-933b-4654f0cf5d0d"
      }
     }
    },
    "efe59041-9754-46cd-9a6f-a04eb76ccbbf": {
     "id": "efe59041-9754-46cd-9a6f-a04eb76ccbbf",
     "prev": "c3f0d508-e7d2-45a1-9b29-91275df5c422",
     "regions": {
      "7c0bb904-8702-44bd-b57b-75e61e7a5a80": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "75676a65-f58b-4f20-b4a0-1cf8f1156d71",
        "part": "whole"
       },
       "id": "7c0bb904-8702-44bd-b57b-75e61e7a5a80"
      }
     }
    },
    "f0743c29-abc3-44be-87d6-dd1d5510322d": {
     "id": "f0743c29-abc3-44be-87d6-dd1d5510322d",
     "prev": "99838ed2-6577-4917-a98b-5b45dbaff5b7",
     "regions": {
      "b058597c-5656-42c4-ae9e-74e567a11d40": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7cfbdcb-9c6c-4b9b-9d3e-c4ff15e0c74c",
        "part": "whole"
       },
       "id": "b058597c-5656-42c4-ae9e-74e567a11d40"
      }
     }
    },
    "f2a530ec-9ccc-485b-b61b-a99a778bbcba": {
     "id": "f2a530ec-9ccc-485b-b61b-a99a778bbcba",
     "prev": "2edca6cb-99a3-4cc0-ad20-0e8a9969f32c",
     "regions": {
      "3f7d423c-0b12-4667-886f-b8c5a8b455de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25aa92a1-20c9-4206-9133-ab31f96cb321",
        "part": "whole"
       },
       "id": "3f7d423c-0b12-4667-886f-b8c5a8b455de"
      }
     }
    },
    "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25": {
     "id": "ffa8bbfc-6d3e-4673-b0dd-4d5721947b25",
     "prev": "b75ebba2-4536-45b6-b14d-734821fc6db5",
     "regions": {
      "66fe2eda-b793-476d-989b-7eeca28e1890": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9c3800be-12ec-43a7-b24a-8cf543daf831",
        "part": "whole"
       },
       "id": "66fe2eda-b793-476d-989b-7eeca28e1890"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
