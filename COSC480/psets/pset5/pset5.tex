\documentclass{article}
\usepackage{amsmath} %This allows me to use the align functionality.
                     %If you find yourself trying to replicate
                     %something you found online, ensure you're
                     %loading the necessary packages!
\usepackage{amsfonts}%Math font
\usepackage{graphicx}%For including graphics
\usepackage{hyperref}%For Hyperlinks
\usepackage{listings}
\usepackage{graphicx}
\usepackage{natbib}        %For the bibliography
\bibliographystyle{apalike}%For the bibliography
\usepackage[margin=1.0in]{geometry}
\usepackage{float}
\begin{document}
%set the size of the graphs to fit nicely on a 8.5x11 sheet
\noindent \textbf{Caio Brighenti }\\
\noindent \textbf{COSC 480 - Learning From Data}\\%\\ gives you a new line
\noindent \textbf{Fall 2019}\\%\\ gives you a new line
\noindent \textbf{Problem Set 4}\vspace{1em}\\
\begin{enumerate}
	\item Show $||w(t)||^2 \leq ||w(t-1)||^2 + ||x(t-1)||^2$ where $x$ is the misclassified observation.
	\\\\ We start by defining more clearly the terms we are considering. $w^{new}$ in the PLA algorithm can be defined as $w^{new} = w + y\cdot x$, where $w$ is the current weight, $x$ the misclassified observation, and $y$ the correct label. Given that $x$ is misclassified, we can know for certain the quantity $y \cdot x$ is negative, as $x$ and $y$ must necessarily have different signs. Thus, we can rewrite this definition as an inequality as follows: $w^{new} \leq w + abs(x)$. $y$ is omitted as simply takes the value $1$. 
	\\\\ We thus know that $w^{new}$ is smaller than or equal to $w$ plus the magnitude of $x$.  Instead of taking the absolute value, we could have used any function that took the magnitude of $x$. Another such example is the norm operation, which squares each component of $x$ and thus cancels out the negatives. Thus, we can rewrite the previous inequality as $||w^{new}||^2 \leq ||w||^2 + ||x||^2$, as taking the norm of each component will still preserve the inequality. Thus we have shown the claim to be true.
	\item Use induction to show $||w(t)||^2 \leq tR^2$.
	\\\\ As we are proceeding by induction, we first show a base case and establish an inductive hypothesis.
	\\\\ \textbf{Base case: } Our base case is that $t=0$. This base is trivial, as when $t=0$ we have:
	\begin{align}
	||w(0)||^2 &\leq 0\cdot R \\
	0 &\leq 0
	\end{align}
	Thus the base case holds.
	\\ \\ \textbf{Inductive hypothesis: } Assume the claim holds for $t-1$. We will show it then holds for $t$.
	\begin{align}
	||w(t)||^2 &\leq ||w||^2 + ||x||^2 && \text{shown in 1} \\
	&\leq (t-1)R^2 + ||x||^2 && \text{inductive hypothesis} \\
	&\leq (t-1)R^2 + R^2 && \text{$||x||$ must be at most $R$} \\
	&\leq tR^2
	\end{align}
	\\ Therefore the claim must be true.
	\item Use the properties found in 1 and 2 to show $\frac{w(t)\cdot w^*}{||w(t)||} \geq \sqrt{t}\frac{M}{R}.$
	\\\\ We start by first slightly modifying the relationship found in 2 in order to remove the squared terms. We simply take the square root of both sides, resulting in the property $||w(t)|| \leq \sqrt{t}R$. We now observe that given an inequality $x \geq y$, we can obtain the inequality $\frac{x}{a} \geq  \frac{y}{b}$, on the condition that $a \leq b$. Using this property, we thus have:
	\begin{align}
	w(t)\cdot w^* &\geq tM \\
	\frac{w(t)\cdot w^*}{||w(t)||} &\geq \frac{t}{\sqrt{t}} \frac{M}{R} \\
	\frac{w(t)\cdot w^*}{||w(t)||} &\geq \sqrt{t} \frac{M}{R} && \frac{x}{\sqrt{x}} = \sqrt{x}
	\end{align}
	Thus the claim is true.
	\item Show that $t \leq \frac{R^2||w^*||^2}{M^2}$
	\\\\ We can arrive at this claim by simply modifying a few terms from the previous problem as follows.
	\begin{align}
	\sqrt{t} \frac{M}{R} &\leq \frac{w(t)\cdot w^*}{||w(t)||} \\
	t \frac{M^2}{R^2} &\leq \frac{w(t)^2 \cdot (w^*)^2}{||w(t)||^2} && \text{square both sides} \\
	t \frac{M^2}{R^2} &\leq (w^*)^2 && w(t)^2 \text{is the dot product of $t$ with $t$, which is the same as $||w(t)||^2$} \\
	t &\leq \frac{R^2||w^*||^2}{M^2} && \text{rearrange}
	\end{align}
	Thus the claim is true.
\end{enumerate}
	

\end{document}
